<p align="left">
    <a href="README.md">English</a> &nbsp; | &nbspä¸­æ–‡&nbsp</a>
</p>
<br><br>

<div align="center">

<picture>
  <source media="(prefers-color-scheme: dark)" srcset="https://raw.githubusercontent.com/01-ai/Yi/main/assets/img/Yi_logo_icon_dark.svg" width="200px">
  <source media="(prefers-color-scheme: light)" srcset="https://raw.githubusercontent.com/01-ai/Yi/main/assets/img/Yi_logo_icon_light.svg" width="200px"> 
  <img alt="specify theme context for images" src="https://raw.githubusercontent.com/01-ai/Yi/main/assets/img/Yi_logo_icon_light.svg" width="200px">
</picture>

</br>
</br>

<a href="https://github.com/01-ai/Yi/actions/workflows/build_docker_image.yml">
  <img src="https://github.com/01-ai/Yi/actions/workflows/build_docker_image.yml/badge.svg">
</a>
<a href="https://github.com/01-ai/Yi/blob/main/LICENSE">
  <img src="https://img.shields.io/badge/Code_License-Apache_2.0-lightblue">
</a>
<a href="https://github.com/01-ai/Yi/blob/main/MODEL_LICENSE_AGREEMENT.txt">
  <img src="https://img.shields.io/badge/Model_License-Yi_License-lightblue">
</a>
<a href="mailto:oss@01.ai">
  <img src="https://img.shields.io/badge/âœ‰ï¸-yi@01.ai-FFE01B">
</a>

<div id="top"></div>

</div>
<div align="center">
  <h3 align="center">æ‰“é€ ä¸‹ä¸€ä»£å¼€æºåŒè¯­å¤§è¯­è¨€æ¨¡å‹</h3>
</div>

<p align="center">
ğŸ¤— <a href="https://huggingface.co/01-ai" target="_blank">Hugging Face</a> â€¢ ğŸ¤– <a href="https://www.modelscope.cn/organization/01ai/" target="_blank">é­”æ­ ModelScope</a> â€¢ âœ¡ï¸ <a href="https://wisemodel.cn/organization/01.AI" target="_blank">å§‹æ™º WiseModel</a>
</p> 

<p align="center">
    ğŸ‘©â€ğŸš€ æ¬¢è¿æ¥ <a href="https://github.com/01-ai/Yi/discussions" target="_blank"> GitHub Discussions</a> è®¨è®ºé—®é¢˜
</p> 
<p align="center">
    ğŸ‘‹ æ¬¢è¿åŠ å…¥<a href="https://discord.gg/hYUwWddeAu" target="_blank"> ğŸ‘¾ Discord </a> æˆ–è€… ğŸ’¬ <a href="https://github.com/01-ai/Yi/issues/43#issuecomment-1827285245" target="_blank"> å¾®ä¿¡ç¾¤ </a>ä¸€èµ·äº¤æµ
</p> 

<p align="center">
    ğŸ“ æ¬¢è¿æŸ¥é˜…<a href="https://arxiv.org/abs/2403.04652"> Yi æŠ€æœ¯æŠ¥å‘Š </a>äº†è§£æ›´å¤š
</p> 

<p align="center">
    ğŸ“š æ¬¢è¿æ¥ <a href="#å­¦ä¹ ä¸­å¿ƒ"> Yi å­¦ä¹ ä¸­å¿ƒ </a>æ¢ç´¢æ–°çŸ¥
</p> 


<hr>

<ul>
  <li>ğŸ™Œ æœ¬æ–‡ç”± Yi å’Œ<a href="#æœ¬æ–‡è´¡çŒ®è€…">ç¤¾åŒºå¿—æ„¿è€…</a>å…±åŒç¿»è¯‘å®Œæˆï¼Œæ„Ÿè°¢æ¯ä¸€ä½ä¼ é€’çŸ¥è¯†çš„<a href="#è‡´è°¢">ç«ç‚¬æ‰‹</a>ã€‚</li> 

  <li>ğŸ¤— æ¬¢è¿å¤§å®¶<a href="https://github.com/01-ai/Yi/discussions/314">åŠ å…¥ã€ŒYi èµ·ç¿»è¯‘ã€</a>ï¼Œå¼€å¯çŸ¥è¯†ä¹‹ç«æ—…ç¨‹ï¼Œå…±ç»˜æŠ€æœ¯å†…å®¹å›¾è°±ã€‚</li>
  
  <li>ğŸ“ æœ¬æ–‡ç¿»è¯‘ä½¿ç”¨äº† <a href="https://huggingface.co/spaces/01-ai/Yi-34B-Chat">Yi-34B-Chat</a>ï¼Œå…³äºç¿»è¯‘æ—¶ä½¿ç”¨çš„ prompt åŠæœ€ä½³å®è·µï¼Œå‚é˜…<a href="https://github.com/01-ai/Yi/wiki/%E7%BF%BB%E8%AF%91%E4%B8%8E%E5%AE%A1%E6%A0%A1%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF#%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8-prompt-%E6%9D%A5%E5%AE%9E%E7%8E%B0%E9%AB%98%E8%B4%A8%E9%87%8F%E7%BF%BB%E8%AF%91">ã€Œå¦‚ä½•ä½¿ç”¨ Prompt æ¥å®ç°é«˜è´¨é‡ç¿»è¯‘ã€</a>å’Œ<a href="https://github.com/01-ai/Yi/wiki/%E7%BF%BB%E8%AF%91%E4%B8%8E%E5%AE%A1%E6%A0%A1%E7%9A%84%E6%AD%A3%E7%A1%AE%E5%A7%BF%E5%8A%BF">ã€Œç¿»è¯‘ä¸å®¡æ ¡çš„æ­£ç¡®å§¿åŠ¿ã€</a>ã€‚</li>
</ul>


<!-- DO NOT REMOVE ME -->

<hr>
<details open>
<summary></b>ğŸ“• ç›®å½•</b></summary>

- [ğŸ“Œ Yi æ˜¯ä»€ä¹ˆ?](#-yi-æ˜¯ä»€ä¹ˆ)
  - [ä»‹ç»](#ä»‹ç»)
  - [æ¨¡å‹](#æ¨¡å‹)
    - [Chat æ¨¡å‹](#chat-æ¨¡å‹)
    - [Base æ¨¡å‹](#base-æ¨¡å‹)
    - [å…¶å®ƒä¿¡æ¯](#å…¶å®ƒä¿¡æ¯)
  - [æœ€æ–°åŠ¨æ€](#æœ€æ–°åŠ¨æ€)
- [ğŸ“Œ å¦‚ä½•ä½¿ç”¨ Yi?](#-å¦‚ä½•ä½¿ç”¨-yi)
  - [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
    - [é€‰æ‹©å­¦ä¹ è·¯å¾„](#é€‰æ‹©å­¦ä¹ è·¯å¾„)
    - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ PyPi (pip install)](#å¿«é€Ÿä¸Šæ‰‹---pypi-pip-install)
    - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ Docker](#å¿«é€Ÿä¸Šæ‰‹---docker)
    - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ conda-lock](#å¿«é€Ÿä¸Šæ‰‹---conda-lock)
    - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ llama.cpp](#å¿«é€Ÿä¸Šæ‰‹---llamacpp)
    - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ Web demo](#å¿«é€Ÿä¸Šæ‰‹---ä½¿ç”¨-web-demo)
  - [å¾®è°ƒ](#å¾®è°ƒ)
  - [é‡åŒ–](#é‡åŒ–)
  - [éƒ¨ç½²](#éƒ¨ç½²)
  - [å­¦ä¹ ä¸­å¿ƒ](#å­¦ä¹ ä¸­å¿ƒ)
- [ğŸ“Œ ä¸ºä»€ä¹ˆé€‰æ‹©Yiï¼Ÿ](#-ä¸ºä»€ä¹ˆé€‰æ‹©-yi)
  - [ç”Ÿæ€](#ç”Ÿæ€)
    - [ä¸Šæ¸¸](#ä¸Šæ¸¸)
    - [ä¸‹æ¸¸](#ä¸‹æ¸¸)
      - [æœåŠ¡](#ä¸‹æ¸¸---æœåŠ¡)
      - [é‡åŒ–](#ä¸‹æ¸¸---é‡åŒ–)
      - [å¾®è°ƒ](#ä¸‹æ¸¸---å¾®è°ƒ)
      - [API](#ä¸‹æ¸¸---api)
  - [åŸºå‡†æµ‹è¯•](#åŸºå‡†æµ‹è¯•)
    - [Chat æ¨¡å‹æ€§èƒ½](#chat-æ¨¡å‹æ€§èƒ½)
    - [Base æ¨¡å‹æ€§èƒ½](#base-æ¨¡å‹æ€§èƒ½)
  - [æŠ€æœ¯æŠ¥å‘Š](#æŠ€æœ¯æŠ¥å‘Š)
    - [å¼•ç”¨](#å¼•ç”¨)
- [ğŸ“Œ è°å¯ä»¥ä½¿ç”¨ Yiï¼Ÿ](#-è°å¯ä»¥ä½¿ç”¨-yi)
- [ğŸ“Œ å…¶å®ƒ](#-å…¶å®ƒ)
  - [è‡´è°¢](#è‡´è°¢)
  - [å…è´£å£°æ˜](#å…è´£å£°æ˜)
  - [è®¸å¯è¯](#è®¸å¯è¯)

</details>

<hr>

# ğŸ“Œ Yi æ˜¯ä»€ä¹ˆ?

## ä»‹ç»

- ğŸ¤– Yi ç³»åˆ—æ¨¡å‹æ˜¯ [01.AI](https://01.ai/) ä»é›¶è®­ç»ƒçš„ä¸‹ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚

- ğŸ™Œ Yi ç³»åˆ—æ¨¡å‹æ˜¯ä¸€ä¸ªåŒè¯­è¯­è¨€æ¨¡å‹ï¼Œåœ¨ 3T å¤šè¯­è¨€è¯­æ–™åº“ä¸Šè®­ç»ƒè€Œæˆï¼Œæ˜¯å…¨çƒæœ€å¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ä¹‹ä¸€ã€‚Yi ç³»åˆ—æ¨¡å‹åœ¨è¯­è¨€è®¤çŸ¥ã€å¸¸è¯†æ¨ç†ã€é˜…è¯»ç†è§£ç­‰æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚ä¾‹å¦‚ï¼Œ

   - Yi-34B-Chat æ¨¡å‹åœ¨ AlpacaEval Leaderboard [æ’åç¬¬äºŒ](https://twitter.com/01AI_Yi/status/1745371506623103087?s=20)ï¼Œ**ä»…æ¬¡äº GPT-4 Turbo**ï¼Œè¶…è¿‡äº† GPT-4ã€Mixtral å’Œ Claude ç­‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆæ•°æ®æˆªæ­¢è‡³ 2024 å¹´ 1 æœˆï¼‰ã€‚

  - Yi-34B æ¨¡å‹åœ¨ [Hugging Face Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard)ï¼ˆé¢„è®­ç»ƒï¼‰ä¸ C-Eval åŸºå‡†æµ‹è¯•ä¸­[è£ç™»æ¦œé¦–](https://mp.weixin.qq.com/s/tLP-fjwYHcXVLqDcrXva2g)ï¼Œ**åœ¨ä¸­æ–‡å’Œè‹±æ–‡è¯­è¨€èƒ½åŠ›æ–¹é¢**å‡è¶…è¿‡äº†å…¶å®ƒå¼€æºæ¨¡å‹ï¼Œä¾‹å¦‚ï¼ŒFalcon-180Bã€Llama-70B å’Œ Claudeï¼ˆæ•°æ®æˆªæ­¢è‡³ 2023 å¹´ 11 æœˆï¼‰ã€‚

  - ğŸ™ ï¼ˆè‡´è°¢ Llama ï¼‰æ„Ÿè°¢ Transformer å’Œ Llama å¼€æºç¤¾åŒºï¼Œä¸ä»…ç®€åŒ–äº†å¼€å‘è€…ä»é›¶å¼€å§‹æ„å»ºå¤§æ¨¡å‹çš„å·¥ä½œï¼Œå¼€å‘è€…è¿˜å¯ä»¥åˆ©ç”¨ Llama ç”Ÿæ€ä¸­ç°æœ‰çš„å·¥å…·ã€åº“å’Œèµ„æºï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚

  <details style="display: inline;"><summary> å¦‚æœä½ å¯¹ Yi ä½¿ç”¨ Llama æ¶æ„åŠå…¶è®¸å¯ä½¿ç”¨æ”¿ç­–æ„Ÿå…´è¶£ï¼Œå‚é˜… <span style="color:  green;">ã€ŒYi ä¸ Llama çš„å…³ç³»ã€ã€‚</span> â¬‡ï¸</summary> <ul> <br>

> ğŸ’¡ ç®€çŸ­æ€»ç»“
> 
> Yi ç³»åˆ—æ¨¡å‹é‡‡ç”¨ä¸Llamaç›¸åŒçš„æ¨¡å‹æ¶æ„ï¼Œä½†å®ƒä»¬**ä¸æ˜¯** Llama çš„è¡ç”Ÿå“ã€‚


- Yi å’Œ Llama éƒ½æ˜¯åŸºäº Transformer ç»“æ„ã€‚å®é™…ä¸Šï¼Œè‡ª 2018 å¹´ä»¥æ¥ï¼ŒTransformer ä¸€ç›´æ˜¯å¤§è¯­è¨€æ¨¡å‹çš„å¸¸ç”¨æ¶æ„ã€‚

- åœ¨ Transformer æ¶æ„çš„åŸºç¡€ä¸Šï¼ŒLlama å‡­å€Ÿå‡ºè‰²çš„ç¨³å®šæ€§ã€å¯é çš„æ”¶æ•›æ€§å’Œå¼ºå¤§çš„å…¼å®¹æ€§ï¼Œæˆä¸ºå¤§å¤šæ•°å…ˆè¿›å¼€æºæ¨¡å‹çš„åŸºçŸ³ã€‚å› æ­¤ï¼ŒLlama ä¹Ÿæˆä¸º Yi ç­‰æ¨¡å‹çš„åŸºç¡€æ¡†æ¶ã€‚

- å¾—ç›Šäº Transformer å’Œ Llama æ¶æ„ï¼Œå„ç±»æ¨¡å‹å¯ä»¥ç®€åŒ–ä»é›¶å¼€å§‹æ„å»ºæ¨¡å‹çš„å·¥ä½œï¼Œå¹¶èƒ½å¤Ÿåœ¨å„è‡ªçš„ç”Ÿæ€ä¸­ä½¿ç”¨ç›¸åŒçš„å·¥å…·ã€‚

- ç„¶è€Œï¼ŒYi ç³»åˆ—æ¨¡å‹ä¸æ˜¯ Llama çš„è¡ç”Ÿå“ï¼Œå› ä¸ºå®ƒä»¬ä¸ä½¿ç”¨ Llama çš„æƒé‡ã€‚

  - è™½ç„¶å¤§å¤šæ•°å¼€æºæ¨¡å‹éƒ½é‡‡ç”¨äº† Llama çš„æ¶æ„ï¼Œä½†å†³å®šæ¨¡å‹è¡¨ç°çš„å…³é”®å› ç´ æ˜¯è®­ç»ƒæ‰€ä½¿ç”¨çš„æ•°æ®é›†ã€è®­ç»ƒç®¡é“åŠå…¶åŸºç¡€è®¾æ–½ã€‚

  - [01.AI](https://01.ai/) ç”¨ç‹¬ç‰¹çš„æ–¹å¼å¼€å‘äº† Yi ç³»åˆ—æ¨¡å‹ï¼Œä»é›¶å¼€å§‹åˆ›å»ºäº†è‡ªå·±çš„é«˜è´¨é‡è®­ç»ƒæ•°æ®é›†ã€é«˜æ•ˆçš„è®­ç»ƒæµæ°´çº¿å’Œå¼ºå¤§çš„è®­ç»ƒåŸºç¡€è®¾æ–½ï¼Œå› æ­¤ Yi ç³»åˆ—æ¨¡å‹æ€§èƒ½ä¼˜å¼‚ï¼Œåœ¨ [Alpaca Leaderboard](https://tatsu-lab.github.io/alpaca_eval/) ä¸Šæ’åä»…æ¬¡äº GPT-4ï¼Œè¶…è¿‡äº† Llamaï¼ˆæ•°æ®æˆªæ­¢è‡³ 2023 å¹´ 12 æœˆï¼‰ã€‚
</ul>
</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>


## æœ€æ–°åŠ¨æ€

<details>
<summary>ğŸ¯ <b>2023-03-16</b>ï¼šå‘å¸ƒå¹¶å¼€æºäº† <code>Yi-9B-200K</code> æ¨¡å‹ã€‚</summary>
</details>

<details open>
  <summary>ğŸ¯ <b>2024-03-08</b>: å‘å¸ƒäº† <a href="https://arxiv.org/abs/2403.04652">Yi æŠ€æœ¯æŠ¥å‘Š</a>ï¼</summary>
  <br>

<details open>
  <summary>ğŸ”” <b>2024-03-07</b>: å¢å¼ºäº† Yi-34B-200K é•¿æ–‡æœ¬è®°å¿†å’Œæ£€ç´¢èƒ½åŠ›ã€‚</summary>
  <br>
Yi-34B-200K çš„â€œå¤§æµ·æé’ˆâ€èƒ½åŠ›å¢å¼ºäº† 10.5%, ä» 89.3% æå‡åˆ°äº† 99.8%ã€‚
åœ¨ 5B tokens çš„é•¿æ–‡æœ¬æ•°æ®é›†ä¸Šï¼Œå¯¹æ¨¡å‹è¿›è¡Œç»§ç»­é¢„è®­ç»ƒï¼Œæ¨¡å‹æ€§èƒ½è¾¾åˆ°é¢„æœŸç›®æ ‡ã€‚

</details>
<br>
<details open>
  <summary>ğŸ¯ <b>2024-03-06</b>: å‘å¸ƒå¹¶å¼€æºäº† <code>Yi-9B</code> æ¨¡å‹ã€‚</summary>
  <br>
<code>Yi-9B</code> æ¨¡å‹åœ¨ Mistral-7Bã€SOLAR-10.7Bã€Gemma-7Bã€DeepSeek-Coder-7B-Base-v1.5 ç­‰ç›¸è¿‘å°ºå¯¸çš„æ¨¡å‹ä¸­ååˆ—å‰èŒ…ï¼Œå…·æœ‰å‡ºè‰²çš„ä»£ç èƒ½åŠ›ã€æ•°å­¦èƒ½åŠ›ã€å¸¸è¯†æ¨ç†èƒ½åŠ›ä»¥åŠé˜…è¯»ç†è§£èƒ½åŠ›ã€‚
</details>
<br>
<details open>
  <summary>ğŸ¯ <b> 2024-01-23</b>: å‘å¸ƒå¹¶å¼€æºäº† <code><a href="https://huggingface.co/01-ai/Yi-VL-34B">Yi-VL-34B</a></code> å’Œ <code><a href="https://huggingface.co/01-ai/Yi-VL-6B">Yi-VL-6B</a></code> å¤šæ¨¡æ€è¯­è¨€å¤§æ¨¡å‹ã€‚</summary>
  <br>
   <code><a href="https://huggingface.co/01-ai/Yi-VL-34B">Yi-VL-34B</a></code>åœ¨ <a href="https://arxiv.org/abs/2311.16502">MMMU</a> å’Œ <a href="https://arxiv.org/abs/2401.11944">CMMMU</a> æœ€æ–°çš„åŸºå‡†æµ‹è¯•ä¸­è£ç™»æ¦œé¦–ï¼ˆæ•°æ®æˆªæ­¢è‡³ 2024 å¹´ 1 æœˆï¼‰ã€‚</li>
</details>
<br>
<details>
<summary>ğŸ¯ <b>2023-11-23</b>: å‘å¸ƒå¹¶å¼€æºäº†å…­å¤§ Chat æ¨¡å‹ã€‚</summary>
<br>
å…¶ä¸­ï¼Œä¸¤ä¸ª 4-bits æ¨¡å‹ç”± AWQ é‡åŒ–ï¼Œä¸¤ä¸ª 8-bits æ¨¡å‹ç”± GPTQ é‡åŒ–ã€‚

- `Yi-34B-Chat`
- `Yi-34B-Chat-4bits`
- `Yi-34B-Chat-8bits`
- `Yi-6B-Chat`
- `Yi-6B-Chat-4bits`
- `Yi-6B-Chat-8bits`

</details>

<details>
<summary>ğŸ”” <b>2023-11-23</b>ï¼š Yi ç³»åˆ—æ¨¡å‹ç¤¾åŒºè®¸å¯åè®®æ›´æ–°è‡³ <a href="https://github.com/01-ai/Yi/blob/main/MODEL_LICENSE_AGREEMENT.txt">2.1 ç‰ˆæœ¬</a>ã€‚</summary>
</details>

<details>  
<summary>ğŸ”¥ <b>2023-11-08</b>ï¼š Yi-34B-Chat æ¨¡å‹å¼€å§‹é‚€è¯·æµ‹è¯•ã€‚</summary>
<br>

å¦‚éœ€ç”³è¯·æµ‹è¯•ï¼Œä½ å¯ä»¥å¡«å†™[è‹±æ–‡](https://cn.mikecrm.com/l91ODJf)æˆ–[ä¸­æ–‡](https://cn.mikecrm.com/gnEZjiQ)ç”³è¯·è¡¨ã€‚

</details>

<details>
<summary>ğŸ¯ <b>2023-11-05</b>ï¼š å‘å¸ƒå¹¶å¼€æºäº† <code>Yi-6B-200K</code> å’Œ <code>Yi-34B-200K</code> Base æ¨¡å‹ã€‚ </summary>
<br>
è¿™ä¸¤ä¸ª Base æ¨¡å‹ä¸ä¹‹å‰å‘å¸ƒçš„ Base æ¨¡å‹çš„å‚æ•°è§„æ¨¡ç›¸åŒï¼Œå¹¶ä¸”ä¸Šä¸‹æ–‡çª—å£æ‰©å±•åˆ°äº† 200Kã€‚

</details>

<details>
<summary>ğŸ¯ <b>2023-11-02</b>ï¼š å‘å¸ƒå¹¶å¼€æºäº† <code>Yi-6B-Base</code> å’Œ <code>Yi-34B-Base</code> æ¨¡å‹ã€‚</summary>
<br>
é¦–æ¬¡å‘å¸ƒå¹¶å¼€æºäº†ä¸¤ä¸ª Base æ¨¡å‹ï¼ˆæ”¯æŒä¸­è‹±åŒè¯­ï¼‰ï¼Œå‚æ•°è§„æ¨¡åˆ†åˆ«ä¸º 6B å’Œ 34Bã€‚ä¸¤è€…å‡ä»¥ 4K åºåˆ—é•¿åº¦è¿›è¡Œè®­ç»ƒï¼Œåœ¨æ¨ç†æ—¶å¯æ‰©å±•åˆ° 32Kã€‚

</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

## æ¨¡å‹
Yi ç³»åˆ—æ¨¡å‹æœ‰å¤šç§å‚æ•°è§„æ¨¡ï¼Œé€‚ç”¨äºä¸åŒçš„ä½¿ç”¨åœºæ™¯ã€‚ä½ ä¹Ÿå¯ä»¥å¯¹Yiæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæ»¡è¶³ç‰¹å®šéœ€æ±‚ã€‚

å¦‚éœ€éƒ¨ç½² Yi ç³»åˆ—æ¨¡å‹ï¼Œåº”ç¡®ä¿è½¯ä»¶å’Œç¡¬ä»¶æ»¡è¶³ã€Œ[éƒ¨ç½²è¦æ±‚](#éƒ¨ç½²)ã€.

### Chat æ¨¡å‹

| æ¨¡å‹ | ä¸‹è½½ 
|---|---
Yi-34B-Chat	| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-34B-Chat)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-34B-Chat/summary)
Yi-34B-Chat-4bits	| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-34B-Chat-4bits)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-34B-Chat-4bits/summary)
Yi-34B-Chat-8bits | â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-34B-Chat-8bits) â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-34B-Chat-8bits/summary)
Yi-6B-Chat| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-6B-Chat) â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-6B-Chat/summary)
Yi-6B-Chat-4bits |	â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-6B-Chat-4bits)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-6B-Chat-4bits/summary)
Yi-6B-Chat-8bits	|  â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-6B-Chat-8bits) â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-6B-Chat-8bits/summary)

<sub><sup> - 4-bits ç³»åˆ—æ¨¡å‹ç”±AWQé‡åŒ–ã€‚<br> - 8-bits ç³»åˆ—æ¨¡å‹ç”±GPTQé‡åŒ–ã€‚<br> - æ‰€æœ‰é‡åŒ–æ¨¡å‹çš„ä½¿ç”¨é—¨æ§›è¾ƒä½ï¼Œå› æ­¤å¯ä»¥åœ¨æ¶ˆè´¹çº§GPUï¼ˆä¾‹å¦‚ï¼Œ3090ã€4090ï¼‰ä¸Šéƒ¨ç½²ã€‚</sup></sub>

### Base æ¨¡å‹

| æ¨¡å‹ | ä¸‹è½½ | 
|---|---|
Yi-34B| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-34B)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-34B/summary)
Yi-34B-200K|â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-34B-200K)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-34B-200K/summary)
Yi-9B|â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-9B) â€¢ [ğŸ¤– ModelScope](https://wisemodel.cn/models/01.AI/Yi-9B)
Yi-9B-200K | â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-9B-200K)   â€¢ [ğŸ¤– ModelScope](https://wisemodel.cn/models/01.AI/Yi-9B-200K)
Yi-6B| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-6B)  â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-6B/summary)
Yi-6B-200K	| â€¢ [ğŸ¤— Hugging Face](https://huggingface.co/01-ai/Yi-6B-200K) â€¢ [ğŸ¤– ModelScope](https://www.modelscope.cn/models/01ai/Yi-6B-200K/summary)

<sub><sup> - 200K å¤§çº¦ç›¸å½“äº 40 ä¸‡ä¸ªæ±‰å­—ã€‚<br> - å¦‚æœä½ æƒ³ç”¨ Yi-34B-200K æ›´æ—©çš„ç‰ˆæœ¬ ï¼ˆå³ 2023 å¹´ 11 æœˆ 5 æ—¥å‘å¸ƒçš„ç‰ˆæœ¬ï¼‰ï¼Œå¯ä»¥è¿è¡Œä»£ç  `git checkout 069cd341d60f4ce4b07ec394e82b79e94f656cf`ï¼Œä¸‹è½½æƒé‡ã€‚</sup></sub>


### æ¨¡å‹ä¿¡æ¯

- For chat and base models

Model | Intro | é»˜è®¤çš„ä¸Šä¸‹æ–‡çª—å£ | é¢„è®­ç»ƒçš„ tokens æ•°é‡ | è®­ç»ƒæ•°æ®
|---|---|---|---|---
6B ç³»åˆ—æ¨¡å‹ |é€‚åˆä¸ªäººå’Œå­¦æœ¯ä½¿ç”¨ã€‚| 4K | 3T | æˆªè‡³ 2023 å¹´ 6 æœˆã€‚
9B æ¨¡å‹| æ˜¯ Yi ç³»åˆ—æ¨¡å‹ä¸­ä»£ç å’Œæ•°å­¦èƒ½åŠ›æœ€å¼ºçš„æ¨¡å‹ã€‚|4K | Yi-9B æ˜¯åœ¨ Yi-6B çš„åŸºç¡€ä¸Šï¼Œä½¿ç”¨äº† 0.8T tokens è¿›è¡Œç»§ç»­è®­ç»ƒã€‚| æˆªè‡³ 2023 å¹´ 6 æœˆã€‚
34B ç³»åˆ—æ¨¡å‹ | é€‚åˆä¸ªäººã€å­¦æœ¯å’Œå•†ä¸šç”¨é€”ï¼ˆå°¤å…¶å¯¹ä¸­å°å‹ä¼ä¸šå‹å¥½ï¼‰ã€‚<br>34B æ¨¡å‹å°ºå¯¸åœ¨å¼€æºç¤¾åŒºå±äºç¨€ç¼ºçš„â€œé»„é‡‘æ¯”ä¾‹â€å°ºå¯¸ï¼Œå·²å…·å¤§æ¨¡å‹æ¶Œç°èƒ½åŠ›ï¼Œé€‚åˆå‘æŒ¥äºå¤šå…ƒåœºæ™¯ï¼Œæ»¡è¶³å¼€æºç¤¾åŒºçš„åˆšæ€§éœ€æ±‚ã€‚|4K | 3T | æˆªè‡³ 2023 å¹´ 6 æœˆã€‚

- Chat æ¨¡å‹
  
  <details style="display: inline;"><summary>å…³äº Chat æ¨¡å‹çš„å±€é™æ€§ï¼Œå‚é˜…ä»¥ä¸‹è§£é‡Šã€‚ â¬‡ï¸</summary> 
   <ul>
   <br> Chat æ¨¡å‹åœ¨è®­ç»ƒä¸­é‡‡ç”¨äº†ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æŠ€æœ¯ã€‚ä¸å…¶å®ƒå¸¸è§„ Chat æ¨¡å‹ç›¸æ¯”ï¼Œ Yi ç³»åˆ—æ¨¡å‹ç”Ÿæˆçš„å›å¤æ›´åŠ å¤šæ ·åŒ–ï¼Œï¼ˆ1ï¼‰å› æ­¤é€‚ç”¨äºå„ç§ä¸‹æ¸¸ä»»åŠ¡ï¼Œä¾‹å¦‚ï¼Œåˆ›æ„åœºæ™¯ï¼›ï¼ˆ2ï¼‰æœ‰åˆ©äºæé«˜å›å¤çš„è´¨é‡ï¼Œå¯¹åç»­çš„å¼ºåŒ–å­¦ä¹ ï¼ˆRLï¼‰è®­ç»ƒå¸®åŠ©å¾ˆå¤§ã€‚

    <br>æ³¨æ„ï¼Œå›å¤å¤šæ ·åŒ–ä¹Ÿå¯èƒ½ä¼šå¯¼è‡´æŸäº›å·²çŸ¥é—®é¢˜æ›´åŠ ä¸¥é‡ï¼Œä¾‹å¦‚ï¼Œ
      <li>å¹»è§‰ï¼šå³æ¨¡å‹å¯èƒ½ä¼šç”Ÿæˆé”™è¯¯æˆ–ä¸è¿è´¯çš„ä¿¡æ¯ã€‚æ¨¡å‹å›å¤å¤šæ ·åŒ–ï¼Œæ›´æœ‰å¯èƒ½å‡ºç°å¹»è§‰ï¼Œè¿™äº›å¹»è§‰å¯èƒ½ä¸æ˜¯åŸºäºå‡†ç¡®çš„æ•°æ®æˆ–é€»è¾‘æ¨ç†ã€‚</li>
      <li>é‡æ–°ç”Ÿæˆçš„å›å¤ä¸ä¸€è‡´ï¼šé‡æ–°ç”Ÿæˆå›å¤æˆ–è€…å¯¹å›å¤è¿›è¡Œé‡‡æ ·æ—¶ï¼Œç»“æœå¯èƒ½å‡ºç°å‰åä¸ä¸€è‡´ã€‚å¤šæ ·æ€§å¢å¤šä¼šå¯¼è‡´å³ä½¿åœ¨ç›¸ä¼¼çš„è¾“å…¥æ¡ä»¶ä¸‹ï¼Œç»“æœä¹Ÿä¼šå­˜åœ¨å·®å¼‚ã€‚</li>
      <li>ç´¯ç§¯è¯¯å·®ï¼šå½“æ¨¡å‹å›å¤çš„é”™è¯¯éšæ—¶é—´ç´¯ç§¯ï¼Œå°±ä¼šå‡ºç°ç´¯è®¡è¯¯å·®çš„ç°è±¡ã€‚æ¨¡å‹å›å¤çš„å¤šæ ·åŒ–å¢åŠ äº†å°è¯¯å·®ç§¯ç´¯æˆå¤§é”™è¯¯çš„å¯èƒ½æ€§ï¼Œè¿™ç§æƒ…å†µå¸¸è§äºæ‰©å±•æ¨ç†ã€è§£å†³æ•°å­¦é—®é¢˜ç­‰å¤æ‚ä»»åŠ¡ä¸­ã€‚</li>
      <li>ä¸ºäº†è·å¾—æ›´è¿è´¯ä¸€è‡´çš„å›å¤ï¼Œå»ºè®®è°ƒæ•´ç”Ÿæˆé…ç½®å‚æ•°ï¼Œä¾‹å¦‚ï¼Œæ¸©åº¦ã€top_p å’Œ top_kã€‚è¿™äº›è°ƒæ•´æ—¢å¯ä»¥è®©æ¨¡å‹çš„å›å¤å¯Œæœ‰åˆ›æ„ï¼Œåˆèƒ½ä¿æŒé€»è¾‘ä¸Šçš„è¿è´¯æ€§ã€‚</li>
</ul>
</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>


# ğŸ“Œ å¦‚ä½•ä½¿ç”¨ Yi?
- [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
  - [é€‰æ‹©å­¦ä¹ è·¯å¾„](#é€‰æ‹©å­¦ä¹ è·¯å¾„)
  - [å¿«é€Ÿä¸Šæ‰‹ - PyPi (pip install)](#å¿«é€Ÿä¸Šæ‰‹---pypi-pip-install)
  - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ Docker](#å¿«é€Ÿä¸Šæ‰‹---docker)
  - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ conda-lock](#å¿«é€Ÿä¸Šæ‰‹---conda-lock)
  - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ llama.cpp](#å¿«é€Ÿä¸Šæ‰‹---llamacpp)
  - [å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ Web demo](#å¿«é€Ÿä¸Šæ‰‹---ä½¿ç”¨-web-demo)
- [å¾®è°ƒ](#å¾®è°ƒ)
- [é‡åŒ–](#é‡åŒ–)
- [éƒ¨ç½²](#éƒ¨ç½²)
- [å­¦ä¹ ä¸­å¿ƒ](#å­¦ä¹ ä¸­å¿ƒ)

## å¿«é€Ÿä¸Šæ‰‹

 ä½ å¯ä»¥é€‰æ‹©ä¸€æ¡å­¦ä¹ è·¯å¾„ï¼Œå¼€å§‹ä½¿ç”¨ Yi ç³»åˆ—æ¨¡å‹ã€‚

### é€‰æ‹©å­¦ä¹ è·¯å¾„

ä½ å¯ä»¥æ ¹æ®è‡ªèº«éœ€æ±‚ï¼Œé€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼Œå¼€å§‹ä½ çš„ Yi ä¹‹æ—…ã€‚

 ![é€‰æ‹©å­¦ä¹ è·¯å¾„](https://github.com/01-ai/Yi/blob/main/assets/img/quick_start_path_CN.png?raw=true)

#### ğŸ¯ åœ¨æœ¬åœ°éƒ¨ç½² Yi

å¦‚æœä½ æƒ³åœ¨æœ¬åœ°éƒ¨ç½² Yi æ¨¡å‹ï¼Œ

  - ğŸ™‹â€â™€ï¸ å¹¶ä¸”ä½ æœ‰**è¶³å¤Ÿ**çš„èµ„æºï¼ˆä¾‹å¦‚ï¼ŒNVIDIA A800 80GBï¼‰ï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ã€‚
    - [pip](#å¿«é€Ÿä¸Šæ‰‹---pypi-pip-install)
    - [Docker](#å¿«é€Ÿä¸Šæ‰‹---docker)
    - [conda-lock](#å¿«é€Ÿä¸Šæ‰‹---conda-lock)
  - ğŸ™‹â€â™€ï¸ ä½†ä½ çš„èµ„æºæœ‰é™ï¼ˆä¾‹å¦‚ï¼Œä¸€å° MacBook Proï¼‰ï¼Œä½ å¯ä»¥ä½¿ç”¨ [llama.cpp](#å¿«é€Ÿä¸Šæ‰‹---llamacpp)ã€‚

#### ğŸ¯ ä¸åœ¨æœ¬åœ°éƒ¨ç½² Yi æ¨¡å‹

å¦‚æœä½ ä¸æƒ³åœ¨æœ¬åœ°éƒ¨ç½² Yi æ¨¡å‹ï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ã€‚

##### ğŸ™‹â€â™€ï¸ ä½¿ç”¨ Yi API

å¦‚æœä½ æƒ³æ¢ç´¢ Yi çš„æ›´å¤šåŠŸèƒ½ï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ã€‚

- Yi APIs ï¼ˆYi å®˜æ–¹ï¼‰
  - [éƒ¨åˆ†ç”³è¯·è€…](https://x.com/01AI_Yi/status/1735728934560600536?s=20)å·²è·å– Yi API keysã€‚Yi å°†å¼€æ”¾æ›´å¤š API keysï¼Œæ•¬è¯·æœŸå¾…ã€‚

- [Yi APIs](https://replicate.com/01-ai/yi-34b-chat/api?tab=nodejs) ï¼ˆReplicateï¼Œç¬¬ä¸‰æ–¹ç½‘ç«™ï¼‰

##### ğŸ™‹â€â™€ï¸ ä½¿ç”¨ Yi Playground

å¦‚æœä½ æƒ³ä¸ Yi èŠå¤©ï¼Œå¹¶ä½¿ç”¨æ›´å¤šè‡ªå®šä¹‰é€‰é¡¹ï¼ˆä¾‹å¦‚ï¼Œç³»ç»Ÿæç¤ºã€æ¸©åº¦ã€é‡å¤æƒ©ç½šç­‰ï¼‰ï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ã€‚
  
  - [Yi-34B-Chat-Playground](https://platform.lingyiwanwu.com/prompt/playground) ï¼ˆYi å®˜æ–¹ï¼‰
    - å¦‚éœ€ä½¿ç”¨ Yi Playground, æ¬¢è¿ç”³è¯·åŠ å…¥ç™½åå•ï¼ˆå¡«å†™[è‹±æ–‡](https://cn.mikecrm.com/l91ODJf)æˆ–è€…[ä¸­æ–‡](https://cn.mikecrm.com/gnEZjiQ)ç”³è¯·è¡¨ï¼‰ã€‚

  - [Yi-34B-Chat-Playground](https://replicate.com/01-ai/yi-34b-chat) (Replicateï¼Œç¬¬ä¸‰æ–¹ç½‘ç«™) 

##### ğŸ™‹â€â™€ï¸ ä½¿ç”¨ Yi Chat

ä»¥ä¸‹æä¾›äº†ç±»ä¼¼çš„ç”¨æˆ·ä½“éªŒï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ï¼Œä¸ Yi èŠå¤©ã€‚

- [Yi-34B-Chat](https://huggingface.co/spaces/01-ai/Yi-34B-Chat)ï¼ˆYi å®˜æ–¹ - Hugging Faceï¼‰
  - ä¸éœ€è¦æ³¨å†Œã€‚

- [Yi-34B-Chat](https://platform.lingyiwanwu.com/)ï¼ˆYi å®˜æ–¹ï¼‰
  - å¦‚éœ€ä½¿ç”¨å®˜æ–¹åœ¨çº¿èŠå¤©æœåŠ¡ï¼Œæ¬¢è¿ç”³è¯·åŠ å…¥ç™½åå•ï¼ˆå¡«å†™[è‹±æ–‡](https://cn.mikecrm.com/l91ODJf)æˆ–[ä¸­æ–‡](https://cn.mikecrm.com/gnEZjiQ)ç”³è¯·è¡¨ï¼‰ã€‚

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### å¿«é€Ÿä¸Šæ‰‹ - PyPi (pip install)

æœ¬æ•™ç¨‹åœ¨é…ç½®ä¸º **A800ï¼ˆ80GBï¼‰** çš„æœ¬åœ°æœºå™¨ä¸Šè¿è¡Œ Yi-34B-Chatï¼Œ å¹¶è¿›è¡Œæ¨ç†ã€‚

#### ç¬¬ 0 æ­¥ï¼šå‰ææ¡ä»¶
 
- ç¡®ä¿å®‰è£…äº† Python 3.10 ä»¥ä¸Šç‰ˆæœ¬ã€‚

- å¦‚æœä½ æƒ³è¿è¡Œ Yi ç³»åˆ—æ¨¡å‹ï¼Œå‚é˜…ã€Œ[éƒ¨ç½²è¦æ±‚](#éƒ¨ç½²)ã€ã€‚

#### ç¬¬ 1 æ­¥ï¼šå‡†å¤‡ç¯å¢ƒ 

å¦‚éœ€è®¾ç½®ç¯å¢ƒï¼Œå®‰è£…æ‰€éœ€è¦çš„è½¯ä»¶åŒ…ï¼Œè¿è¡Œä¸‹é¢çš„å‘½ä»¤ã€‚

```bash
git clone https://github.com/01-ai/Yi.git
cd yi
pip install -r requirements.txt
```

#### ç¬¬ 2 æ­¥ï¼šä¸‹è½½æ¨¡å‹

ä½ å¯ä»¥ä»ä»¥ä¸‹æ¥æºä¸‹è½½ Yi æ¨¡å‹ã€‚

- [Hugging Face](https://huggingface.co/01-ai)
- [ModelScope](https://www.modelscope.cn/organization/01ai/)
- [WiseModel](https://wisemodel.cn/organization/01.AI)

#### ç¬¬ 3 æ­¥ï¼šè¿›è¡Œæ¨ç†

ä½ å¯ä»¥ä½¿ç”¨ Yi Chat æ¨¡å‹æˆ– Base æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚

##### ä½¿ç”¨ Yi Chat æ¨¡å‹è¿›è¡Œæ¨ç†

1. åˆ›å»ºä¸€ä¸ªåä¸º `quick_start.py` çš„æ–‡ä»¶ï¼Œå¹¶å°†ä»¥ä¸‹å†…å®¹å¤åˆ¶åˆ°è¯¥æ–‡ä»¶ä¸­ã€‚

    ```python
    from transformers import AutoModelForCausalLM, AutoTokenizer

    model_path = '<your-model-path>'

    tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=False)

    # Since transformers 4.35.0, the GPT-Q/AWQ model can be loaded using AutoModelForCausalLM.
    model = AutoModelForCausalLM.from_pretrained(
        model_path,
        device_map="auto",
        torch_dtype='auto'
    ).eval()

    # Prompt content: "hi"
    messages = [
        {"role": "user", "content": "hi"}
    ]

    input_ids = tokenizer.apply_chat_template(conversation=messages, tokenize=True, add_generation_prompt=True, return_tensors='pt')
    output_ids = model.generate(input_ids.to('cuda'))
    response = tokenizer.decode(output_ids[0][input_ids.shape[1]:], skip_special_tokens=True)

    # Model response: "Hello! How can I assist you today?"
    print(response)
    ```

2. è¿è¡Œ `quick_start.py` ä»£ç ã€‚

    ```bash
    python quick_start.py
    ```

    ä½ å°†å¾—åˆ°ä¸€ä¸ªç±»ä¼¼è¾“å‡ºï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ğŸ¥³

    ```bash
    Hello! How can I assist you today?
    ```

##### ä½¿ç”¨ Yi Base æ¨¡å‹è¿›è¡Œæ¨ç†

- Yi-34B

æ­¥éª¤ä¸ã€Œ[ä½¿ç”¨ Yi Chat æ¨¡å‹è¿›è¡Œæ¨ç†](#ä½¿ç”¨-yi-chat-æ¨¡å‹è¿›è¡Œæ¨ç†)ã€ç±»ä¼¼ã€‚

ä½ å¯ä»¥ä½¿ç”¨ç°æœ‰æ–‡ä»¶ [`text_generation.py`](https://github.com/01-ai/Yi/tree/main/demo)è¿›è¡Œæ¨ç†ã€‚

```bash
python demo/text_generation.py  --model <your-model-path>
```

<details>

<summary> ä½ å°†å¾—åˆ°ä¸€ä¸ªç±»ä¼¼è¾“å‡ºï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚ğŸ¥³ â¬‡ï¸ </summary>

<br>

**æŒ‡ä»¤**ï¼š Let me tell you an interesting story about cat Tom and mouse Jerry,

**å›å¤**ï¼š Let me tell you an interesting story about cat Tom and mouse Jerry, which happened in my childhood. My father had a big house with two cats living inside it to kill mice. One day when I was playing at home alone, I found one of the tomcats lying on his back near our kitchen door, looking very much like he wanted something from us but couldnâ€™t get up because there were too many people around him! He kept trying for several minutes before finally giving up...

</details>
<br>

- Yi-9B
  
  è¾“å…¥

  ```bash
  from transformers import AutoModelForCausalLM, AutoTokenizer

  MODEL_DIR = "01-ai/Yi-9B"
  model = AutoModelForCausalLM.from_pretrained(MODEL_DIR, torch_dtype="auto")
  tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR, use_fast=False)

  input_text = "# write the quick sort algorithm"
  inputs = tokenizer(input_text, return_tensors="pt").to(model.device)
  outputs = model.generate(**inputs, max_length=256)
  print(tokenizer.decode(outputs[0], skip_special_tokens=True))
  ```

  è¾“å‡º

  ```bash
  # write the quick sort algorithm
  def quick_sort(arr):
      if len(arr) <= 1:
          return arr
      pivot = arr[len(arr) // 2]
      left = [x for x in arr if x < pivot]
      middle = [x for x in arr if x == pivot]
      right = [x for x in arr if x > pivot]
      return quick_sort(left) + middle + quick_sort(right)

  # test the quick sort algorithm
  print(quick_sort([3, 6, 8, 10, 1, 2, 1]))
  ```

    <p align="right"> [
    <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
  </p>


<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### å¿«é€Ÿä¸Šæ‰‹ - Docker

<details>
<summary> ğŸš€ æ•™ç¨‹ï¼šåœ¨æœ¬åœ° Docker ä¸Šè¿è¡Œ Yi-34B-Chatã€‚â¬‡ï¸</summary>
<br>æœ¬æ•™ç¨‹åœ¨æœ¬åœ° Dockerï¼ˆé…ç½®ä¸º A800 GPU æˆ– 4*4090ï¼‰ä¸Šè¿è¡Œ <strong>Yi-34B-Chat</strong> æ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¨ç†ã€‚
<h4>ç¬¬ 0 æ­¥ï¼šå‡†å¤‡å·¥ä½œ</h4>
<p>ç¡®ä¿ä½ å·²ç»å®‰è£…äº† <a href="https://docs.docker.com/engine/install/?open_in_browser=true">Docker</a> å’Œ <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">nvidia-container-toolkit</a>ã€‚</p>
<h4>ç¬¬ 1 æ­¥ï¼šå¯åŠ¨ Docker</h4>
<pre><code>docker run -it --gpus all \
-v &lt;your-model-path&gt;: /models
ghcr.io/01-ai/yi:latest
</code></pre>
<p>æˆ–è€…ï¼Œä½ ä¹Ÿå¯ä»¥ä»<code>registry.lingyiwanwu.com/ci/01-ai/yi:latest</code> æ‹‰å–å·²ç»æ„å»ºå¥½çš„ Yi Docker é•œåƒã€‚</p>

<h4>ç¬¬ 2 æ­¥ï¼šè¿›è¡Œæ¨ç†</h4>
    <p>ä½ å¯ä»¥ä½¿ç”¨ Yi çš„ Chat æ¨¡å‹æˆ– Base æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚</p>
    
<h5>ä½¿ç”¨ Yi Chat æ¨¡å‹è¿›è¡Œæ¨ç†</h5>
    <p>è¿›è¡Œæ¨ç†çš„æ­¥éª¤ä¸ã€Œ<a href="#ä½¿ç”¨-yi-chat-æ¨¡å‹è¿›è¡Œæ¨ç†"> åœ¨ pip ä¸Šä½¿ç”¨ Yi Chat æ¨¡å‹è¿›è¡Œæ¨ç† </a>ã€ç±»ä¼¼ã€‚</p>
    <p><strong>æ³¨æ„ï¼š</strong> å”¯ä¸€ä¸åŒçš„æ˜¯ä½ éœ€è¦è®¾ç½® <code>model_path</code> ä¸º <code>= '&lt;your-model-mount-path&gt;'</code> è€Œä¸æ˜¯ <code>= '&lt;your-model-path&gt;'</code>ã€‚</p>
<h5>ä½¿ç”¨ Yi Base æ¨¡å‹è¿›è¡Œæ¨ç†</h5>
    <p>è¿›è¡Œæ¨ç†çš„æ­¥éª¤ä¸ã€Œ<a href="#ä½¿ç”¨-yi-chat-æ¨¡å‹è¿›è¡Œæ¨ç†"> åœ¨ pip ä¸Šä½¿ç”¨ Yi Chat æ¨¡å‹è¿›è¡Œæ¨ç† </a>ã€ç±»ä¼¼ã€‚</p>
    <p><strong>æ³¨æ„ï¼š</strong> å”¯ä¸€ä¸åŒçš„æ˜¯ä½ éœ€è¦è®¾ç½® <code>model_path</code> ä¸º <code>= '&lt;your-model-mount-path&gt;'</code> è€Œä¸æ˜¯ <code>= '&lt;your-model-path&gt;'</code>ã€‚</p>
</details>

### å¿«é€Ÿä¸Šæ‰‹ - conda-lock

<details>
<summary> ğŸš€ å¦‚éœ€åˆ›å»ºä¸€ä¸ªå¯ä»¥å®Œå…¨é‡ç°çš„ conda ç¯å¢ƒé”å®šæ–‡ä»¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ <code><a href="https://github.com/conda/conda-lock">conda-lock</a></code> å·¥å…·ã€‚ â¬‡ï¸</summary>
<br>
ä½ å¯ä»¥å‚è€ƒ  <a href="https://github.com/01-ai/Yi/blob/ebba23451d780f35e74a780987ad377553134f68/conda-lock.yml">conda-lock.yml</a> æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶åŒ…å«äº†æ‰€éœ€ä¾èµ–é¡¹çš„å…·ä½“ç‰ˆæœ¬ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œä½ è¿˜å¯ä»¥ä½¿ç”¨<code><a href="https://mamba.readthedocs.io/en/latest/user_guide/micromamba.html">micromamba</a></code>å·¥å…·æ¥å®‰è£…è¿™äº›ä¾èµ–é¡¹ã€‚
<br>
å®‰è£…è¿™äº›ä¾èµ–é¡¹çš„æ­¥éª¤ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

1. æ ¹æ®<a href="https://mamba.readthedocs.io/en/latest/installation/micromamba-installation.html">æŒ‡å—</a>å®‰è£… "micromamba"ã€‚ 

2. è¿è¡Œå‘½ä»¤ <code>micromamba install -y -n yi -f conda-lock.yml</code> ï¼Œåˆ›å»ºä¸€ä¸ªåä¸º<code>yi</code> conda ç¯å¢ƒï¼Œå¹¶å®‰è£…æ‰€éœ€çš„ä¾èµ–é¡¹ã€‚
</details>

### å¿«é€Ÿä¸Šæ‰‹ - llama.cpp
<details>
<summary> ğŸš€ æ•™ç¨‹ï¼šåœ¨æœ¬åœ° llama.cpp ä¸Šè¿è¡Œ Yi-chat-6B-2bitsã€‚â¬‡ï¸ </summary> 
<br>æœ¬æ•™ç¨‹åœ¨æœ¬åœ° llama.cpp ä¸Šè¿è¡Œ <a href="https://huggingface.co/XeIaso/yi-chat-6B-GGUF/tree/main">Yi-chat-6B-2bits</a> é‡åŒ–æ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¨ç†ã€‚</p>

- [æ­¥éª¤ 0ï¼šå‰ææ¡ä»¶](#æ­¥éª¤-0å‰ææ¡ä»¶)
- [æ­¥éª¤ 1ï¼šä¸‹è½½ llama.cpp](#æ­¥éª¤-1ä¸‹è½½-llamacpp)
- [æ­¥éª¤ 2ï¼šä¸‹è½½æ¨¡å‹](#æ­¥éª¤-2ä¸‹è½½æ¨¡å‹)
- [æ­¥éª¤ 3ï¼šè¿›è¡Œæ¨ç†](#æ­¥éª¤-3è¿›è¡Œæ¨ç†)

#### æ­¥éª¤ 0ï¼šå‰ææ¡ä»¶

- è¯¥æ•™ç¨‹é€‚ç”¨äº MacBook Proï¼ˆ16GB å†…å­˜å’Œ Apple M2 Pro èŠ¯ç‰‡ï¼‰ã€‚

- ç¡®ä¿ä½ çš„ç”µè„‘ä¸Šå®‰è£…äº† [`git-lfs`](https://git-lfs.com/) ã€‚
  
#### æ­¥éª¤ 1ï¼šä¸‹è½½ `llama.cpp`

å¦‚éœ€å…‹éš† [`llama.cpp`](https://github.com/ggerganov/llama.cpp) ä»“åº“ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```bash
git clone git@github.com:ggerganov/llama.cpp.git
```

#### æ­¥éª¤ 2ï¼šä¸‹è½½æ¨¡å‹

æ­¥éª¤ 2.1ï¼šä»…ä¸‹è½½ [XeIaso/yi-chat-6B-GGUF](https://huggingface.co/XeIaso/yi-chat-6B-GGUF/tree/main) ä»“åº“çš„ pointersï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```bash
GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/XeIaso/yi-chat-6B-GGUF
```

æ­¥éª¤ 2.2ï¼šä¸‹è½½é‡åŒ–åçš„ Yi æ¨¡å‹ [yi-chat-6b.Q2_K.gguf](https://huggingface.co/XeIaso/yi-chat-6B-GGUF/blob/main/yi-chat-6b.Q2_K.gguf)ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```bash
git-lfs pull --include yi-chat-6b.Q2_K.gguf
```

#### æ­¥éª¤ 3ï¼šè¿›è¡Œæ¨ç†

å¦‚éœ€ä½“éªŒ Yi æ¨¡å‹ï¼ˆè¿è¡Œæ¨¡å‹æ¨ç†ï¼‰ï¼Œä½ å¯ä»¥é€‰æ‹©ä»¥ä¸‹æ–¹å¼ä¹‹ä¸€ã€‚

- [æ–¹å¼ 1ï¼šåœ¨ç»ˆç«¯ä¸­è¿›è¡Œæ¨ç†](#æ–¹å¼-1åœ¨ç»ˆç«¯ä¸­è¿›è¡Œæ¨ç†)
  
- [æ–¹å¼ 2ï¼šåœ¨ Webä¸Šè¿›è¡Œæ¨ç†](#æ–¹å¼-2åœ¨ Webä¸Šè¿›è¡Œæ¨ç†)

##### æ–¹å¼ 1ï¼šåœ¨ç»ˆç«¯ä¸­è¿›è¡Œæ¨ç†

æœ¬æ–‡ä½¿ç”¨ 4 ä¸ªçº¿ç¨‹ç¼–è¯‘ `llama.cpp` ï¼Œä¹‹åè¿›è¡Œæ¨ç†ã€‚åœ¨ `llama.cpp` æ‰€åœ¨çš„ç›®å½•ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

> ###### æç¤º
>
> - å°† `/Users/yu/yi-chat-6B-GGUF/yi-chat-6b.Q2_K.gguf` æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹çš„å®é™…è·¯å¾„ã€‚
>
> - é»˜è®¤æƒ…å†µä¸‹ï¼Œæ¨¡å‹æ˜¯ç»­å†™æ¨¡å¼ï¼ˆcompletion modeï¼‰ã€‚
> - å¦‚éœ€æŸ¥çœ‹æ›´å¤šè‡ªå®šä¹‰é€‰é¡¹ï¼ˆä¾‹å¦‚ï¼Œç³»ç»Ÿæç¤ºã€æ¸©åº¦ã€é‡å¤æƒ©ç½šç­‰ï¼‰ï¼Œè¿è¡Œ `./main -h` æŸ¥çœ‹è¯¦ç»†ä½¿ç”¨è¯´æ˜ã€‚

```bash
make -j4 && ./main -m /Users/yu/yi-chat-6B-GGUF/yi-chat-6b.Q2_K.gguf -p "How do you feed your pet fox? Please answer this question in 6 simple steps:\nStep 1:" -n 384 -e

...

How do you feed your pet fox? Please answer this question in 6 simple steps:

Step 1: Select the appropriate food for your pet fox. You should choose high-quality, balanced prey items that are suitable for their unique dietary needs. These could include live or frozen mice, rats, pigeons, or other small mammals, as well as fresh fruits and vegetables.

Step 2: Feed your pet fox once or twice a day, depending on the species and its individual preferences. Always ensure that they have access to fresh water throughout the day.

Step 3: Provide an appropriate environment for your pet fox. Ensure it has a comfortable place to rest, plenty of space to move around, and opportunities to play and exercise.

Step 4: Socialize your pet with other animals if possible. Interactions with other creatures can help them develop social skills and prevent boredom or stress.

Step 5: Regularly check for signs of illness or discomfort in your fox. Be prepared to provide veterinary care as needed, especially for common issues such as parasites, dental health problems, or infections.

Step 6: Educate yourself about the needs of your pet fox and be aware of any potential risks or concerns that could affect their well-being. Regularly consult with a veterinarian to ensure you are providing the best care.

...

```

æ­å–œä½ ï¼ä½ å·²ç»æˆåŠŸåœ°å‘ Yi æ¨¡å‹æå‡ºäº†é—®é¢˜ï¼Œå¾—åˆ°äº†å›å¤ï¼ğŸ¥³

##### æ–¹å¼ 2ï¼šåœ¨ Webä¸Šè¿›è¡Œæ¨ç†

1. å¦‚éœ€å¯ç”¨ä¸€ä¸ªè½»ä¾¿æ•æ·çš„èŠå¤©æœºå™¨äººï¼Œä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

    ```bash
    ./server --ctx-size 2048 --host 0.0.0.0 --n-gpu-layers 64 --model /Users/yu/yi-chat-6B-GGUF/yi-chat-6b.Q2_K.gguf
    ```

    ä½ å°†å¾—åˆ°ä¸€ä¸ªç±»ä¼¼è¾“å‡ºã€‚

    ```bash
    ...

    llama_new_context_with_model: n_ctx      = 2048
    llama_new_context_with_model: freq_base  = 5000000.0
    llama_new_context_with_model: freq_scale = 1
    ggml_metal_init: allocating
    ggml_metal_init: found device: Apple M2 Pro
    ggml_metal_init: picking default device: Apple M2 Pro
    ggml_metal_init: ggml.metallib not found, loading from source
    ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil
    ggml_metal_init: loading '/Users/yu/llama.cpp/ggml-metal.metal'
    ggml_metal_init: GPU name:   Apple M2 Pro
    ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)
    ggml_metal_init: hasUnifiedMemory              = true
    ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB
    ggml_metal_init: maxTransferRate               = built-in GPU
    ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   128.00 MiB, ( 2629.44 / 10922.67)
    llama_new_context_with_model: KV self size  =  128.00 MiB, K (f16):   64.00 MiB, V (f16):   64.00 MiB
    ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 2629.45 / 10922.67)
    llama_build_graph: non-view tensors processed: 676/676
    llama_new_context_with_model: compute buffer total size = 159.19 MiB
    ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   156.02 MiB, ( 2785.45 / 10922.67)
    Available slots:
    -> Slot 0 - max context: 2048

    llama server listening at http://0.0.0.0:8080
    ```

2. å¦‚éœ€è®¿é—®èŠå¤©æœºå™¨äººç•Œé¢ï¼Œå¯ä»¥æ‰“å¼€ç½‘ç»œæµè§ˆå™¨ï¼Œåœ¨åœ°å€æ ä¸­è¾“å…¥ `http://0.0.0.0:8080`ã€‚

    ![Yiæ¨¡å‹èŠå¤©æœºå™¨äººç•Œé¢ - LLaMA.cpp](https://github.com/01-ai/Yi/blob/main/assets/img/yi_llama_cpp1.png?raw=true)

3. å¦‚æœä½ åœ¨æç¤ºçª—å£ä¸­è¾“å…¥é—®é¢˜ï¼Œä¾‹å¦‚ï¼Œâ€œå¦‚ä½•å–‚å…»ä½ çš„å® ç‰©ç‹ç‹¸ï¼Ÿè¯·ç”¨ 6 ä¸ªç®€å•çš„æ­¥éª¤å›ç­”â€ï¼Œä½ å°†æ”¶åˆ°ç±»ä¼¼çš„å›å¤ã€‚

    ![å‘ Yi æ¨¡å‹æé—® - LLaMA.cpp](https://github.com/01-ai/Yi/blob/main/assets/img/yi_llama_cpp2.png?raw=true)

</ul>
</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### å¿«é€Ÿä¸Šæ‰‹ - ä½¿ç”¨ Web demo

ä½ å¯ä»¥ä½¿ç”¨ **Yi Chat æ¨¡å‹**ï¼ˆYi-34B-Chatï¼‰åˆ›å»º Web demoã€‚
**æ³¨æ„**ï¼šYi Base æ¨¡å‹ï¼ˆYi-34Bï¼‰ä¸æ”¯æŒè¯¥åŠŸèƒ½ã€‚

[ç¬¬ä¸€æ­¥ï¼šå‡†å¤‡ç¯å¢ƒ](#ç¬¬-1-æ­¥å‡†å¤‡ç¯å¢ƒ)

[ç¬¬äºŒæ­¥ï¼šä¸‹è½½æ¨¡å‹](#ç¬¬-2-æ­¥ä¸‹è½½æ¨¡å‹)

ç¬¬ä¸‰æ­¥ï¼šå¯åŠ¨ Web demo æœåŠ¡ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```bash
python demo/web_demo.py -c <ä½ çš„æ¨¡å‹è·¯å¾„>
```

å‘½ä»¤è¿è¡Œå®Œæ¯•åï¼Œä½ å¯ä»¥åœ¨æµè§ˆå™¨ä¸­è¾“å…¥æ§åˆ¶å°æä¾›çš„ç½‘å€ï¼Œæ¥ä½¿ç”¨ Web demo åŠŸèƒ½ã€‚

 ![å¿«é€Ÿä¸Šæ‰‹ -  Web demo](https://github.com/01-ai/Yi/blob/main/assets/img/yi_34b_chat_web_demo.gif?raw=true)

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### å¾®è°ƒ

```bash
bash finetune/scripts/run_sft_Yi_6b.sh
```

å®Œæˆåï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ï¼Œæ¯”è¾ƒå¾®è°ƒåçš„æ¨¡å‹ä¸ Base æ¨¡å‹ã€‚

```bash
bash finetune/scripts/run_eval.sh
```
<details style="display: inline;"><summary> ä½ å¯ä»¥ä½¿ç”¨ Yi 6B å’Œ 34B Base æ¨¡å‹çš„å¾®è°ƒä»£ç ï¼Œæ ¹æ®ä½ çš„è‡ªå®šä¹‰æ•°æ®è¿›è¡Œå¾®è°ƒã€‚ â¬‡ï¸</summary> <ul>

#### å‡†å¤‡å·¥ä½œ

###### ä»é•œåƒå¼€å§‹

é»˜è®¤æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¥è‡ª[BAAI/COIG](https://huggingface.co/datasets/BAAI/COIG) çš„å°å‹æ•°æ®é›†æ¥å¾®è°ƒ Base æ¨¡å‹ã€‚
ä½ è¿˜å¯ä»¥æŒ‰ç…§ä»¥ä¸‹ `jsonl` æ ¼å¼å‡†å¤‡è‡ªå®šä¹‰æ•°æ®é›†ã€‚

```json
{ "prompt": "Human: Who are you? Assistant:", "chosen": "I'm Yi." }
```
ç„¶åå°†è‡ªå®šä¹‰æ•°æ®é›†æŒ‚è½½åˆ°å®¹å™¨ä¸­ï¼Œæ›¿æ¢é»˜è®¤æ•°æ®ã€‚

```bash
docker run -it \
    -v /path/to/save/finetuned/model/:/finetuned-model \
    -v /path/to/train.jsonl:/yi/finetune/data/train.json \
    -v /path/to/eval.jsonl:/yi/finetune/data/eval.json \
    ghcr.io/01-ai/yi:latest \
    bash finetune/scripts/run_sft_Yi_6b.sh
```

###### ä»æœ¬åœ°æœåŠ¡å™¨å¼€å§‹

ç¡®ä¿ä½ å·²ç»å®‰è£…äº† condaã€‚å¦‚éœ€å®‰è£… condaï¼Œ ä½ å¯ä»¥è¿è¡Œä»¥ä¸‹å‘½ä»¤ã€‚

```bash
mkdir -p ~/miniconda3
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh
bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3
rm -rf ~/miniconda3/miniconda.sh
~/miniconda3/bin/conda init bash
source ~/.bashrc
```

ç„¶åï¼Œåˆ›å»ºä¸€ä¸ª conda ç¯å¢ƒã€‚

```bash
conda create -n dev_env python=3.10 -y
conda activate dev_env
pip install torch==2.0.1 deepspeed==0.10 tensorboard transformers datasets sentencepiece accelerate ray==2.7
```

##### é…å¤‡ç¡¬ä»¶

å¦‚æœä½ æƒ³ä½¿ç”¨ Yi-6B æ¨¡å‹ï¼Œå»ºè®®ä½¿ç”¨å…·æœ‰ 4 ä¸ª GPU çš„èŠ‚ç‚¹ï¼Œæ¯ä¸ª GPU å†…å­˜å¤§äº 60GBã€‚

å¦‚æœä½ æƒ³ä½¿ç”¨ Yi-34B æ¨¡å‹ï¼Œ**æ³¨æ„**æ­¤æ¨¡å¼é‡‡ç”¨é›¶å¸è½½æŠ€æœ¯ï¼Œå ç”¨äº†å¤§é‡ CPU å†…å­˜ï¼Œå› æ­¤éœ€è¦é™åˆ¶ 34B å¾®è°ƒè®­ç»ƒä¸­çš„ GPU æ•°é‡ã€‚ä½ å¯ä»¥ä½¿ç”¨ CUDA_VISIBLE_DEVICES é™åˆ¶ GPU æ•°é‡ï¼ˆå¦‚ scripts/run_sft_Yi_34b.sh ä¸­æ‰€ç¤ºï¼‰ã€‚

ç”¨äºå¾®è°ƒ 34B æ¨¡å‹çš„å¸¸ç”¨ç¡¬ä»¶å…·æœ‰ 8 ä¸ª GPU çš„èŠ‚ç‚¹ï¼ˆé€šè¿‡CUDA_VISIBLE_DEVICES=0,1,2,3 åœ¨è¿è¡Œä¸­é™åˆ¶ä¸º4ä¸ª GPUï¼‰ï¼Œæ¯ä¸ª GPU çš„å†…å­˜å¤§äº 80GBï¼Œæ€» CPU å†…å­˜å¤§äº900GBã€‚

#### å¿«é€Ÿä¸Šæ‰‹

å°† LLM-base æ¨¡å‹ä¸‹è½½åˆ° MODEL_PATHï¼ˆ6B å’Œ 34Bï¼‰ã€‚æ¨¡å‹å¸¸è§çš„æ–‡ä»¶å¤¹ç»“æ„å¦‚ä¸‹ã€‚

```bash
|-- $MODEL_PATH
|   |-- config.json
|   |-- pytorch_model-00001-of-00002.bin
|   |-- pytorch_model-00002-of-00002.bin
|   |-- pytorch_model.bin.index.json
|   |-- tokenizer_config.json
|   |-- tokenizer.model
|   |-- ...
```

å°†æ•°æ®é›†ä» Hugging Face ä¸‹è½½åˆ°æœ¬åœ°å­˜å‚¨ DATA_PATHï¼Œä¾‹å¦‚ï¼Œ Dahoas/rm-staticã€‚

```bash
|-- $DATA_PATH
|   |-- data
|   |   |-- train-00000-of-00001-2a1df75c6bce91ab.parquet
|   |   |-- test-00000-of-00001-8c7c51afc6d45980.parquet
|   |-- dataset_infos.json
|   |-- README.md
```

`finetune/yi_example_dataset` ä¸­æœ‰ç¤ºä¾‹æ•°æ®é›†ï¼Œè¿™äº›æ•°æ®é›†æ˜¯ä» [BAAI/COIG](https://huggingface.co/datasets/BAAI/COIG)ä¿®æ”¹è€Œæ¥ã€‚

```bash
|-- $DATA_PATH
    |--data
        |-- train.jsonl
        |-- eval.jsonl
```

`cd` è¿›å…¥ scripts æ–‡ä»¶å¤¹ï¼Œå¤åˆ¶å¹¶ç²˜è´´è„šæœ¬ï¼Œç„¶åè¿è¡Œã€‚ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç å®Œæˆæ­¤é¡¹ã€‚

```bash
cd finetune/scripts

bash run_sft_Yi_6b.sh
```

å¯¹äº Yi-6B-Base æ¨¡å‹ï¼Œè®¾ç½® training_debug_steps=20 å’Œ num_train_epochs=4ï¼Œ å°±å¯ä»¥è¾“å‡ºä¸€ä¸ª Chat æ¨¡å‹ï¼Œå¤§çº¦éœ€è¦ 20 åˆ†é’Ÿã€‚

å¯¹äº Yi-34B-Base æ¨¡å‹ï¼Œåˆå§‹åŒ–æ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚

#### è¯„ä¼°

```bash
cd finetune/scripts

bash run_eval.sh
```

ä½ å°†å¾—åˆ° Base æ¨¡å‹å’Œå¾®è°ƒæ¨¡å‹çš„å›å¤ã€‚
</ul>
</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### é‡åŒ–

#### GPT-Q é‡åŒ–
```bash
python quantization/gptq/quant_autogptq.py \
  --model /base_model                      \
  --output_dir /quantized_model            \
  --trust_remote_code
```

å¦‚éœ€è¯„ä¼°ç”Ÿæˆçš„æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ã€‚

```bash
python quantization/gptq/eval_quantized_model.py \
  --model /quantized_model                       \
  --trust_remote_code
```

<details style="display: inline;"><summary> è¯¦ç»†çš„é‡åŒ–è¿‡ç¨‹ã€‚ â¬‡ï¸</summary> <ul>
<br>

[GPT-Q](https://github.com/IST-DASLab/gptq) æ˜¯ä¸€ç§åè®­ç»ƒé‡åŒ–æ–¹æ³•ï¼Œèƒ½å¤Ÿå¸®åŠ©å¤§å‹è¯­è¨€æ¨¡å‹åœ¨ä½¿ç”¨æ—¶èŠ‚çœå†…å­˜ï¼Œä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œå¹¶åŠ å¿«æ¨¡å‹çš„è¿è¡Œé€Ÿåº¦ã€‚

å¦‚éœ€å¯¹ Yi æ¨¡å‹è¿›è¡Œ GPT-Q é‡åŒ–ï¼Œä½¿ç”¨ä»¥ä¸‹æ•™ç¨‹ã€‚

è¿è¡Œ GPT-Q éœ€è¦ä½¿ç”¨ [AutoGPTQ](https://github.com/PanQiWei/AutoGPTQ) å’Œ [exllama](https://github.com/turboderp/exllama)ã€‚
æ­¤å¤–ï¼ŒHugging Face Transformers å·²ç»é›†æˆäº† optimum å’Œ auto-gptqï¼Œèƒ½å¤Ÿå®ç°è¯­è¨€æ¨¡å‹çš„ GPT-Q é‡åŒ–ã€‚

##### é‡åŒ–æ¨¡å‹

å¦‚éœ€é‡åŒ–æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ `quant_autogptq.py` è„šæœ¬ã€‚

```bash
python quant_autogptq.py --model /base_model \
    --output_dir /quantized_model --bits 4 --group_size 128 --trust_remote_code
```

##### è¿è¡Œé‡åŒ–æ¨¡å‹

å¦‚éœ€è¿è¡Œé‡åŒ–æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ `eval_quantized_model.py` è„šæœ¬ã€‚

```bash
python eval_quantized_model.py --model /quantized_model --trust_remote_code
```
</ul>
</details>

#### AWQ é‡åŒ–
```bash
python quantization/awq/quant_autoawq.py \
  --model /base_model                      \
  --output_dir /quantized_model            \
  --trust_remote_code
```

å¦‚éœ€è¯„ä¼°ç”Ÿæˆçš„æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç ã€‚

```bash
python quantization/awq/eval_quantized_model.py \
  --model /quantized_model                       \
  --trust_remote_code
```
<details style="display: inline;"><summary> è¯¦ç»†çš„é‡åŒ–è¿‡ç¨‹ã€‚â¬‡ï¸</summary> <ul>
<br>

[AWQ](https://github.com/mit-han-lab/llm-awq)æ˜¯ä¸€ç§åè®­ç»ƒé‡åŒ–æ–¹æ³•ï¼Œå¯ä»¥å°†æ¨¡å‹çš„æƒé‡æ•°æ®é«˜æ•ˆå‡†ç¡®åœ°è½¬åŒ–æˆä½ä½æ•°æ®ï¼ˆä¾‹å¦‚ï¼ŒINT3 æˆ– INT4ï¼‰ï¼Œå› æ­¤å¯ä»¥å‡å°æ¨¡å‹å ç”¨çš„å†…å­˜ç©ºé—´ï¼Œä¿æŒæ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

å¦‚éœ€å¯¹ Yi æ¨¡å‹è¿›è¡Œ AWQ é‡åŒ–ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ•™ç¨‹ã€‚

è¿è¡Œ AWQ éœ€è¦ä½¿ç”¨ [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)ã€‚

##### é‡åŒ–æ¨¡å‹

å¦‚éœ€é‡åŒ–æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ `quant_autoawq.py` è„šæœ¬ã€‚

```bash
python quant_autoawq.py --model /base_model \
    --output_dir /quantized_model --bits 4 --group_size 128 --trust_remote_code
```

##### è¿è¡Œé‡åŒ–æ¨¡å‹

å¦‚éœ€è¿è¡Œé‡åŒ–æ¨¡å‹ï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹ `eval_quantized_model.py` è„šæœ¬ã€‚

```bash
python eval_quantized_model.py --model /quantized_model --trust_remote_code
```


</ul>
</details>

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### éƒ¨ç½²

å¦‚æœä½ æƒ³éƒ¨ç½² Yi æ¨¡å‹ï¼Œç¡®ä¿æ»¡è¶³ä»¥ä¸‹è½¯ä»¶å’Œç¡¬ä»¶è¦æ±‚ã€‚

#### è½¯ä»¶è¦æ±‚

åœ¨ä½¿ç”¨ Yi é‡åŒ–æ¨¡å‹ä¹‹å‰ï¼Œç¡®ä¿å®‰è£…ä»¥ä¸‹è½¯ä»¶ã€‚

| æ¨¡å‹ | è½¯ä»¶ |
|:---|:---|
Yi 4-bits é‡åŒ–æ¨¡å‹ | [AWQ å’Œ CUDA](https://github.com/casper-hansen/AutoAWQ?tab=readme-ov-file#install-from-pypi)
Yi 8-bits é‡åŒ–æ¨¡å‹ |  [GPTQ å’Œ CUDA](https://github.com/PanQiWei/AutoGPTQ?tab=readme-ov-file#quick-installation)

#### ç¡¬ä»¶è¦æ±‚

éƒ¨ç½² Yi ç³»åˆ—æ¨¡å‹ä¹‹å‰ï¼Œç¡®ä¿ç¡¬ä»¶æ»¡è¶³ä»¥ä¸‹è¦æ±‚ã€‚

##### Chat æ¨¡å‹

| æ¨¡å‹                 | æœ€ä½æ˜¾å­˜      | æ¨è GPU ç¤ºä¾‹                             |
|:----------------------|:--------------|:-------------------------------------:|
| Yi-6B-Chat           | 15 GB         | 1 x RTX 3090 (24 GB) <br> 1 x RTX 4090 (24 GB) <br>  1 x A10 (24 GB)  <br> 1 x A30 (24 GB)              |
| Yi-6B-Chat-4bits     | 4 GB          | 1 x RTX 3060 (12 GB)<br> 1 x RTX 4060 (8 GB)                   |
| Yi-6B-Chat-8bits     | 8 GB          | 1 x RTX 3070 (8 GB) <br> 1 x RTX 4060 (8 GB)                   |
| Yi-34B-Chat          | 72 GB         | 4 x RTX 4090 (24 GB)<br> 1 x A800 (80GB)               |
| Yi-34B-Chat-4bits    | 20 GB         | 1 x RTX 3090 (24 GB) <br> 1 x RTX 4090 (24 GB) <br> 1 x A10 (24 GB)  <br> 1 x A30 (24 GB)  <br> 1 x A100 (40 GB) |
| Yi-34B-Chat-8bits    | 38 GB         | 2 x RTX 3090 (24 GB) <br> 2 x RTX 4090 (24 GB)<br> 1 x A800  (40 GB) |

ä»¥ä¸‹æ˜¯ä¸åŒ batch ä½¿ç”¨æƒ…å†µä¸‹çš„æœ€ä½æ˜¾å­˜è¦æ±‚ã€‚

|  æ¨¡å‹                  | batch=1 | batch=4 | batch=16 | batch=32 |
| :----------------------- | :------- | :------- | :-------- | :-------- |
| Yi-6B-Chat              | 12 GB   | 13 GB   | 15 GB    | 18 GB    |
| Yi-6B-Chat-4bits  | 4 GB    | 5 GB    | 7 GB     | 10 GB    |
| Yi-6B-Chat-8bits  | 7 GB    | 8 GB    | 10 GB    | 14 GB    |
| Yi-34B-Chat       | 65 GB   | 68 GB   | 76 GB    | > 80 GB   |
| Yi-34B-Chat-4bits | 19 GB   | 20 GB   | 30 GB    | 40 GB    |
| Yi-34B-Chat-8bits | 35 GB   | 37 GB   | 46 GB    | 58 GB    |

##### Base æ¨¡å‹

|æ¨¡å‹                   |æœ€ä½æ˜¾å­˜      |        æ¨èGPUç¤ºä¾‹                     |
|:----------------------|:--------------|:-------------------------------------:|
| Yi-6B                | 15 GB         | 1 x RTX 3090 (24 GB) <br> 1 x RTX 4090 (24 GB) <br> 1 x A10 (24 GB)  <br> 1 x A30 (24 GB)                |
| Yi-6B-200K           | 50 GB         | 1 x A800 (80 GB)                            |
| Yi-9B                | 20 GB         | 1 x RTX 4090 (24 GB)                           |
| Yi-34B               | 72 GB         | 4 x RTX 4090 (24 GB) <br> 1 x A800 (80 GB)               |
| Yi-34B-200K          | 200 GB        | 4 x A800 (80 GB)                        |

### å­¦ä¹ ä¸­å¿ƒ

<details>
<summary> å¦‚æœä½ æƒ³å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Yi ç³»åˆ—æ¨¡å‹ï¼Œè¿™é‡Œæœ‰ä¸°å¯Œçš„å­¦ä¹ èµ„æºã€‚ â¬‡ï¸</summary>
<br>

æ¬¢è¿æ¥åˆ° Yi å­¦ä¹ ä¸­å¿ƒï¼

æ— è®ºä½ æ˜¯ç»éªŒä¸°å¯Œçš„ä¸“å®¶è¿˜æ˜¯åˆå‡ºèŒ…åºçš„æ–°æ‰‹ï¼Œä½ éƒ½å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°ä¸°å¯Œçš„å­¦ä¹ èµ„æºï¼Œå¢é•¿æœ‰å…³ Yi æ¨¡å‹çš„çŸ¥è¯†ï¼Œæå‡ç›¸å…³æŠ€èƒ½ã€‚è¿™é‡Œçš„åšå®¢æ–‡ç« å…·æœ‰æ·±åˆ»çš„è§è§£ï¼Œè§†é¢‘æ•™ç¨‹å†…å®¹å…¨é¢ï¼Œå®è·µæŒ‡å—å¯å®æ“æ€§å¼ºï¼Œè¿™äº›å­¦ä¹ èµ„æºéƒ½å¯ä»¥åŠ©ä½ ä¸€è‡‚ä¹‹åŠ›ã€‚

æ„Ÿè°¢å„ä½ Yi ä¸“å®¶å’Œç”¨æˆ·åˆ†äº«äº†è®¸å¤šæ·±åº¦çš„æŠ€æœ¯å†…å®¹ï¼Œæˆ‘ä»¬å¯¹å„ä½å°ä¼™ä¼´çš„å®è´µè´¡çŒ®è¡¨ç¤ºè¡·å¿ƒçš„æ„Ÿè°¢ï¼

åœ¨æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿçƒ­çƒˆé‚€è¯·ä½ åŠ å…¥æˆ‘ä»¬ï¼Œä¸º Yi åšå‡ºè´¡çŒ®ã€‚å¦‚æœä½ åˆ›ä½œäº†å…³äº Yi ç³»åˆ—æ¨¡å‹çš„å†…å®¹ï¼Œæ¬¢è¿æäº¤ PR åˆ†äº«ï¼ğŸ™Œ 

æœ‰äº†è¿™äº›å­¦ä¹ èµ„æºï¼Œä½ å¯ä»¥ç«‹å³å¼€å¯ Yi å­¦ä¹ ä¹‹æ—…ã€‚ç¥å­¦ä¹ æ„‰å¿«ï¼ğŸ¥³

#### æ•™ç¨‹
##### è‹±æ–‡æ•™ç¨‹
| ç±»å‹        | æ•™ç¨‹                                                      |      æ—¥æœŸ      |     ä½œè€…     |
|:-------------|:--------------------------------------------------------|:----------------|:----------------|
| åšå®¢        | [Running Yi-34B-Chat locally using LlamaEdge](https://www.secondstate.io/articles/yi-34b/)                   |  2023-11-30  |  [Second State](https://github.com/second-state)  |
| è§†é¢‘       | [Install Yi 34B Locally - Chinese English Bilingual LLM](https://www.youtube.com/watch?v=CVQvj4Wrh4w&t=476s) | 2023-11-05  | [Fahd Mirza](https://www.youtube.com/@fahdmirza) |
| è§†é¢‘       | [Dolphin Yi 34b - Brand New Foundational Model TESTED](https://www.youtube.com/watch?v=On3Zuv27V3k&t=85s) | 2023-11-27  |  [Matthew Berman](https://www.youtube.com/@matthew_berman)  |

##### ä¸­æ–‡æ•™ç¨‹
| ç±»å‹        | æ•™ç¨‹                                                      |      æ—¥æœŸ      |     ä½œè€…     |
|:-------------|:--------------------------------------------------------|:----------------|:----------------|
| åšå®¢        | [å®æµ‹é›¶ä¸€ä¸‡ç‰©Yi-VLå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼šèƒ½å‡†ç¡®â€œè¯†å›¾åƒç“œâ€](https://mp.weixin.qq.com/s/fu4O9XvJ03JhimsEyI-SsQ)              |  2024-02-02  |  [è‹æ´‹](https://github.com/soulteary)  |
| åšå®¢        | [æœ¬åœ°è¿è¡Œé›¶ä¸€ä¸‡ç‰© 34B å¤§æ¨¡å‹ï¼Œä½¿ç”¨ LLaMA.cpp & 21G æ˜¾å­˜](https://zhuanlan.zhihu.com/p/668921042)                  |  2023-11-26  |  [è‹æ´‹](https://github.com/soulteary)  |
| åšå®¢       | [é›¶ä¸€ä¸‡ç‰©æ¨¡å‹æŠ˜è…¾ç¬”è®°ï¼šå®˜æ–¹ Yi-34B æ¨¡å‹åŸºç¡€ä½¿ç”¨](https://zhuanlan.zhihu.com/p/671387298)                           | 2023-12-10 |  [è‹æ´‹](https://github.com/soulteary)  |
| åšå®¢        | [CPU æ··åˆæ¨ç†ï¼Œéå¸¸è§å¤§æ¨¡å‹é‡åŒ–æ–¹æ¡ˆï¼šâ€œäºŒä¸‰äº”å…­â€ ä½é‡åŒ–æ–¹æ¡ˆ](https://zhuanlan.zhihu.com/p/671698216)                  | 2023-12-12 |  [è‹æ´‹](https://github.com/soulteary)  |
| åšå®¢        | [å•å¡ 3 å°æ—¶è®­ç»ƒ Yi-6B å¤§æ¨¡å‹ Agentï¼šåŸºäº LLaMA Factory å®æˆ˜](https://zhuanlan.zhihu.com/p/678989191)             | 2024-01-22 | [éƒ‘è€€å¨](https://github.com/hiyouga) |
| åšå®¢        | [é›¶ä¸€ä¸‡ç‰©å¼€æºYi-VLå¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œé­”æ­ç¤¾åŒºæ¨ç†&å¾®è°ƒæœ€ä½³å®è·µæ¥å•¦ï¼](https://zhuanlan.zhihu.com/p/680098411)                  | 2024-01-26 |  [ModelScope](https://github.com/modelscope)  |
| è§†é¢‘       | [åªéœ€ 24G æ˜¾å­˜ï¼Œç”¨ vllm è·‘èµ·æ¥ Yi-34B ä¸­è‹±åŒè¯­å¤§æ¨¡å‹](https://www.bilibili.com/video/BV17t4y1f7Ee/)               | 2023-12-28 |  [æ¼†å¦®å¦®](https://space.bilibili.com/1262370256)  |
| è§†é¢‘       | [Yi-VL-34B å¤šæ¨¡æ€å¤§æ¨¡å‹ - ç”¨ä¸¤å¼  A40 æ˜¾å¡è·‘èµ·æ¥](https://www.bilibili.com/video/BV1Q5411y7AG/)               | 2023-01-28 |  [æ¼†å¦®å¦®](https://space.bilibili.com/1262370256)  |
</details>

# ğŸ“Œ ä¸ºä»€ä¹ˆé€‰æ‹© Yiï¼Ÿ

  - [ç”Ÿæ€](#ç”Ÿæ€)
    - [ä¸Šæ¸¸](#ä¸Šæ¸¸)
    - [ä¸‹æ¸¸](#ä¸‹æ¸¸)
      - [æœåŠ¡](#æœåŠ¡)
      - [é‡åŒ–](#ï¸é‡åŒ–)
      - [å¾®è°ƒ](#ï¸å¾®è°ƒ)
      - [API](#api)
  - [åŸºå‡†æµ‹è¯•](#-åŸºå‡†æµ‹è¯•)
    - [Chat æ¨¡å‹æ€§èƒ½](#chat-æ¨¡å‹æ€§èƒ½)
    - [Base æ¨¡å‹æ€§èƒ½](#base-æ¨¡å‹æ€§èƒ½)
      - [Yi-34B å’Œ Yi-34B-200K](#yi-34b-å’Œ-yi-34b-200k)
      - [Yi-9B](#yi-9b)
## ç”Ÿæ€

Yi ç”Ÿæ€ä¸ºä½ æä¾›ä¸€ç³»åˆ—å·¥å…·ã€æœåŠ¡å’Œæ¨¡å‹ï¼Œä½ å°†è·å¾—ä¸°å¯Œçš„ä½“éªŒï¼Œæœ€å¤§ç¨‹åº¦æå‡å·¥ä½œå·¥ä½œæ•ˆç‡ã€‚

- [ä¸Šæ¸¸](#ä¸Šæ¸¸)
- [ä¸‹æ¸¸](#ä¸‹æ¸¸)
  - [æœåŠ¡](#ä¸‹æ¸¸---æœåŠ¡)
  - [é‡åŒ–](#ä¸‹æ¸¸---é‡åŒ–)
  - [å¾®è°ƒ](#ä¸‹æ¸¸---å¾®è°ƒ)
  - [API](#ä¸‹æ¸¸---api)

### ä¸Šæ¸¸

Yi ç³»åˆ—æ¨¡å‹éµå¾ªä¸ Llama ç›¸åŒçš„æ¨¡å‹æ¶æ„ã€‚é€‰æ‹© Yiï¼Œä½ å¯ä»¥åˆ©ç”¨ Llama ç”Ÿæ€ä¸­ç°æœ‰çš„å·¥å…·ã€åº“å’Œèµ„æºï¼Œæ— éœ€åˆ›å»ºæ–°å·¥å…·ï¼Œæé«˜å¼€å‘æ•ˆç‡ã€‚

ä¾‹å¦‚ï¼ŒYi ç³»åˆ—æ¨¡å‹ä»¥ Llama æ¨¡å‹çš„æ ¼å¼ä¿å­˜ã€‚ä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ `LlamaForCausalLM` å’Œ `LlamaTokenizer` åŠ è½½æ¨¡å‹ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç ã€‚

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained("01-ai/Yi-34b", use_fast=False)

model = AutoModelForCausalLM.from_pretrained("01-ai/Yi-34b", device_map="auto")
```
<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### ä¸‹æ¸¸

> ğŸ’¡ æç¤º
> 
> - å¦‚æœä½ å¼€å‘äº†ä¸ Yi ç›¸å…³çš„æœåŠ¡ã€æ¨¡å‹ã€å·¥å…·ã€å¹³å°æˆ–å…¶å®ƒå†…å®¹ï¼Œæ¬¢è¿æäº¤ PRï¼Œå°†ä½ çš„æˆæœå±•ç¤ºåœ¨ [Yi ç”Ÿæ€](#ä¸‹æ¸¸---æœåŠ¡)ã€‚
>
> - ä¸ºäº†å¸®åŠ©ä»–äººå¿«é€Ÿç†è§£ä½ çš„å·¥ä½œï¼Œå»ºè®®ä½¿ç”¨`<æ¨¡å‹åç§°>: <æ¨¡å‹ç®€ä»‹> + <æ¨¡å‹äº®ç‚¹>`çš„æ ¼å¼ã€‚

#### ä¸‹æ¸¸ - æœåŠ¡

å¦‚æœä½ æƒ³åœ¨å‡ åˆ†é’Ÿå†…å¼€å§‹ä½¿ç”¨ Yiï¼Œä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹åŸºäº Yi æ„å»ºçš„æœåŠ¡ã€‚

- Yi-34B-Chatï¼šä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å¹³å°ä¸ Yi èŠå¤©ã€‚
  - [Yi-34B-Chat | Hugging Face](https://huggingface.co/spaces/01-ai/Yi-34B-Chat)
  - [Yi-34B-Chat | Yi Platform](https://platform.lingyiwanwu.com/)
  **æ³¨æ„**ï¼šå¦‚éœ€ä½¿ç”¨ Yi Platform, ä½ å¯ä»¥ç”³è¯·åŠ å…¥ç™½åå•ï¼ˆå¡«å†™[è‹±æ–‡](https://cn.mikecrm.com/l91ODJf)æˆ–[ä¸­æ–‡](https://cn.mikecrm.com/gnEZjiQ)ç”³è¯·è¡¨ï¼‰ã€‚

- [Yi-6B-Chat (Replicate)](https://replicate.com/01-ai)ï¼šä½¿ç”¨è¯¥å·¥å…·ï¼Œä½ å¯ä»¥è®¾ç½®è‡ªå®šä¹‰å‚æ•°ï¼Œè°ƒç”¨ APIs æ¥ä½¿ç”¨ Yi-6B-Chatã€‚

- [ScaleLLM](https://github.com/vectorch-ai/ScaleLLM#supported-models)ï¼šä½ å¯ä»¥ä½¿ç”¨è¯¥å·¥å…·åœ¨æœ¬åœ°è¿è¡Œ Yi æ¨¡å‹ï¼Œæ ¹æ®è‡ªèº«åå¥½è¿›è¡Œä¸ªæ€§åŒ–è®¾ç½®ã€‚

#### ä¸‹æ¸¸ - é‡åŒ–

å¦‚æœèµ„æºæœ‰é™ï¼Œä½ å¯ä»¥ä½¿ç”¨ Yi çš„é‡åŒ–æ¨¡å‹ï¼Œå¦‚ä¸‹æ‰€ç¤ºã€‚

è¿™äº›é‡åŒ–æ¨¡å‹è™½ç„¶ç²¾åº¦é™ä½ï¼Œä½†æ•ˆç‡æ›´é«˜ï¼Œä¾‹å¦‚ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«ï¼ŒRAM ä½¿ç”¨é‡æ›´å°ã€‚

- [TheBloke/Yi-34B-GPTQ](https://huggingface.co/TheBloke/Yi-34B-GPTQ)
- [TheBloke/Yi-34B-GGUF](https://huggingface.co/TheBloke/Yi-34B-GGUF)
- [TheBloke/Yi-34B-AWQ](https://huggingface.co/TheBloke/Yi-34B-AWQ)

#### ä¸‹æ¸¸ - å¾®è°ƒ

å¦‚æœä½ å¸Œæœ›æ¢ç´¢ Yi çš„å…¶å®ƒå¾®è°ƒæ¨¡å‹ï¼Œä½ å¯ä»¥å°è¯•ä»¥ä¸‹æ–¹å¼ã€‚

- [TheBloke æ¨¡å‹](https://huggingface.co/TheBloke)ï¼šè¯¥ç½‘ç«™æä¾›äº†å¤§é‡å¾®è°ƒæ¨¡å‹ï¼Œè¿™äº›å¾®è°ƒæ¨¡å‹åŸºäºå¤šç§å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ Yi æ¨¡å‹ã€‚
  
  ä»¥ä¸‹æ˜¯ Yi çš„å¾®è°ƒæ¨¡å‹ï¼Œæ ¹æ®ä¸‹è½½é‡æ’åºï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»¥ä¸‹æ¨¡å‹ã€‚
  - [TheBloke/dolphin-2_2-yi-34b-AWQ](https://huggingface.co/TheBloke/dolphin-2_2-yi-34b-AWQ)
  - [TheBloke/Yi-34B-Chat-AWQ](https://huggingface.co/TheBloke/Yi-34B-Chat-AWQ)
  - [TheBloke/Yi-34B-Chat-GPTQ](https://huggingface.co/TheBloke/Yi-34B-Chat-GPTQ)
  
- [SUSTech/SUS-Chat-34B](https://huggingface.co/SUSTech/SUS-Chat-34B)ï¼šè¯¥æ¨¡å‹åœ¨æ‰€æœ‰ 70B ä»¥ä¸‹çš„æ¨¡å‹ä¸­æ’åç¬¬ä¸€ï¼Œè¶…è¶Šäº†ä½“é‡æ˜¯å…¶ä¸¤å€çš„ deepseek-llm-67b-chatã€‚ä½ å¯ä»¥åœ¨ [Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) ä¸ŠæŸ¥çœ‹ç»“æœã€‚
  
- [OrionStarAI/OrionStar-Yi-34B-Chat-Llama](https://huggingface.co/OrionStarAI/OrionStar-Yi-34B-Chat-Llama)ï¼šè¯¥æ¨¡å‹åœ¨ C-Eval å’Œ CMMLU è¯„ä¼°ä¸­è¶…è¶Šäº†å…¶å®ƒæ¨¡å‹ï¼ˆä¾‹å¦‚ï¼ŒGPT-4ã€Qwen-14B-Chat å’Œ Baichuan2-13B-Chatï¼‰ï¼Œåœ¨ [OpenCompass LLM Leaderboard](https://opencompass.org.cn/leaderboard-llm) ä¸Šè¡¨ç°å‡ºè‰²ã€‚
  
- [NousResearch/Nous-Capybara-34B](https://huggingface.co/NousResearch/Nous-Capybara-34B)ï¼šè¯¥æ¨¡å‹åœ¨ Capybara æ•°æ®é›†ä¸Šä½¿ç”¨ 200K ä¸Šä¸‹æ–‡é•¿åº¦å’Œ 3 ä¸ª epochs è¿›è¡Œè®­ç»ƒã€‚

#### ä¸‹æ¸¸ - API

- [amazing-openai-api](https://github.com/soulteary/amazing-openai-api)ï¼šæ­¤å·¥å…·å¯ä»¥å°† Yi æ¨¡å‹ API è½¬æ¢æˆ OpenAI API æ ¼å¼ã€‚
- [LlamaEdge](https://www.secondstate.io/articles/yi-34b/#create-an-openai-compatible-api-service-for-the-yi-34b-chat-model)ï¼šä½ å¯ä»¥é€šè¿‡è¯¥å·¥å…·å¿«é€Ÿéƒ¨ç½² Yi-34B-Chat å¹¶å¼€å§‹èŠå¤©ã€‚è¯¥å·¥å…·ç”± Rust è¯­è¨€å¼€å‘ï¼Œä½¿ç”¨å¯ç§»æ¤çš„ Wasmï¼ˆWebAssemblyï¼‰æ–‡ä»¶æ„å»ºäº†ä¸€ä¸ªä¸ OpenAI å…¼å®¹çš„ API æœåŠ¡å™¨ã€‚

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

## åŸºå‡†æµ‹è¯• 

- [Chat æ¨¡å‹æ€§èƒ½](#chat-æ¨¡å‹æ€§èƒ½)
- [Base æ¨¡å‹æ€§èƒ½](#base-æ¨¡å‹æ€§èƒ½)

### Chat æ¨¡å‹æ€§èƒ½

Yi-34B-Chat æ¨¡å‹è¡¨ç°å‡ºè‰²ï¼Œåœ¨ MMLUã€CMMLUã€BBHã€GSM8k ç­‰æ‰€æœ‰å¼€æºæ¨¡å‹çš„åŸºå‡†æµ‹è¯•ä¸­æ’åç¬¬ä¸€ã€‚
<br>

![Chat model performance](https://github.com/01-ai/Yi/blob/main/assets/img/benchmark_chat.png?raw=true) 

<details>
<summary> æµ‹è¯„æ–¹æ³•ä¸æŒ‘æˆ˜ â¬‡ï¸ </summary>

- **è¯„ä¼°æ–¹å¼**ï¼š è¯¥æµ‹è¯„ä½¿ç”¨ zero-shot å’Œ few-shot æ–¹æ³•è¯„ä¼°äº†é™¤ TruthfulQA ä»¥å¤–çš„å„ç§åŸºå‡†ã€‚
- **zero-shot æ–¹æ³•**ï¼š å¤§éƒ¨åˆ† Chat æ¨¡å‹å¸¸ç”¨ zero-shot æ–¹æ³•ã€‚
- **è¯„ä¼°ç­–ç•¥**ï¼š æœ¬æ¬¡æµ‹è¯„çš„è¯„ä¼°ç­–ç•¥æ˜¯è¦æ±‚æ¨¡å‹åœ¨ç»™å‡ºæ˜ç¡®æŒ‡ä»¤æˆ–åŒ…å«éšå«ä¿¡æ¯çš„æŒ‡ä»¤æƒ…å†µä¸‹éµå¾ªæŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼Œä½¿ç”¨å°‘é‡æ ·æœ¬ç¤ºä¾‹ï¼‰ï¼Œç”Ÿæˆå›åº”ï¼Œå¹¶ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æå–ç›¸å…³ç­”æ¡ˆã€‚
- **é¢ä¸´çš„æŒ‘æˆ˜**ï¼š ä¸€äº›æ¨¡å‹ä¸é€‚ç”¨å°‘æ•°æ•°æ®é›†ä¸­çš„æŒ‡ä»¤ï¼Œæ— æ³•æŒ‰ç…§æ‰€è¦æ±‚çš„ç‰¹å®šæ ¼å¼äº§ç”Ÿè¾“å‡ºï¼Œè¿™ä¼šå¯¼è‡´ç»“æœä¸ç†æƒ³ã€‚

<strong>*</strong>ï¼š C-Eval çš„ç»“æœæ¥æºäºéªŒè¯æ•°æ®é›†ã€‚
</details>

### Base æ¨¡å‹æ€§èƒ½


#### Yi-34B å’Œ Yi-34B-200K 

Yi-34B å’Œ Yi-34B-200K æ¨¡å‹åœ¨å¼€æºæ¨¡å‹ä¸­è„±é¢–è€Œå‡ºï¼Œå°¤å…¶åœ¨ MMLUã€CMMLUã€å¸¸è¯†æ¨ç†ã€é˜…è¯»ç†è§£ç­‰æ–¹é¢è¡¨ç°å“è¶Šã€‚
<br>

![Base model performance](https://github.com/01-ai/Yi/blob/main/assets/img/benchmark_base.png?raw=true)

<details>
<summary> æµ‹è¯„æ–¹æ³• â¬‡ï¸</summary>

- **ç»“æœå·®å¼‚**ï¼š åœ¨æµ‹è¯•å¼€æºæ¨¡å‹æ—¶ï¼Œè¯¥æµ‹è¯•çš„æµç¨‹ä¸å…¶å®ƒæµ‹è¯•æ–¹æ³•ï¼ˆä¾‹å¦‚ï¼ŒOpenCompassï¼‰æŠ¥å‘Šçš„ç»“æœä¹‹é—´å­˜åœ¨å·®å¼‚ã€‚
- **ç»“æœå‘ç°**ï¼š æµ‹è¯„ç»“æœæ˜¾ç¤ºï¼Œå„ç§æ¨¡å‹åœ¨ Promptã€åå¤„ç†ç­–ç•¥å’Œé‡‡æ ·æŠ€æœ¯ä¸Šçš„ä¸åŒä¹‹å¤„å¯èƒ½å¯¼è‡´å„ç§æ¨¡å‹çš„ç»“æœäº§ç”Ÿæ˜¾è‘—å·®å¼‚ã€‚
- **ç›¸åŒçš„æµ‹è¯•è¿‡ç¨‹**ï¼š è¯¥æµ‹è¯•çš„æ–¹æ³•è®ºä¸åŸå§‹åŸºå‡†ä¸€è‡´ï¼Œå³åœ¨è¯„ä¼°æ—¶ä½¿ç”¨ç›¸åŒçš„æç¤ºè¯­å’Œåå¤„ç†ç­–ç•¥ï¼Œå¹¶åœ¨è¯„ä¼°æ—¶åº”ç”¨è´ªå¿ƒè§£ç ï¼ˆgreedy decodingï¼‰ï¼Œä¸å¯¹ç”Ÿæˆå†…å®¹è¿›è¡Œä»»ä½•åå¤„ç†ã€‚
- **æµ‹è¯„å…¶å®ƒæ¨¡å‹**ï¼š å¯¹äºæœªæä¾›æµ‹è¯„ç»“æœçš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ä»¥ä¸åŒè®¾ç½®æŠ¥å‘Šçš„åˆ†æ•°ï¼‰ï¼Œè¯¥æµ‹è¯„å°è¯•ä½¿ç”¨è‡ªèº«çš„æµç¨‹è·å–ç»“æœã€‚
- **è¯„ä¼°ç»´åº¦å…¨é¢**ï¼š ä¸ºäº†å…¨é¢è¯„ä¼°æ¨¡å‹çš„èƒ½åŠ›ï¼Œè¯¥æµ‹è¯„é‡‡ç”¨äº†åœ¨ Llama2 ä¸­æ¦‚è¿°çš„æ–¹æ³•ã€‚å…·ä½“è€Œè¨€ï¼Œé’ˆå¯¹å°è¯•æ¨ç†æ–¹é¢ï¼Œè¯¥æµ‹è¯„ä½¿ç”¨äº† PIQAã€SIQAã€HellaSwagã€WinoGrandeã€ARCã€OBQA å’Œ CSQA ç­‰æ–¹æ³•ã€‚é’ˆå¯¹é˜…è¯»ç†è§£æ–¹é¢ï¼Œè¯¥æµ‹è¯„ä½¿ç”¨äº† SquADã€QuAC å’Œ BoolQ ç­‰æ–¹æ³•ã€‚
- **ç‰¹æ®Šè®¾ç½®**ï¼š CSQA ä¸“é—¨ä½¿ç”¨ 7-shot è®¾ç½®è¿›è¡Œæµ‹è¯•ï¼Œè€Œå…¶å®ƒæ‰€æœ‰æµ‹è¯•éƒ½ä½¿ç”¨ 0-shot è®¾ç½®è¿›è¡Œã€‚æ­¤å¤–ï¼Œè¯¥æµ‹è¯„åœ¨â€œæ•°å­¦å’Œç¼–ç â€ç±»åˆ«ä¸‹å¼•å…¥äº† GSM8Kï¼ˆ8-shot@1ï¼‰ã€MATHï¼ˆ4-shot@1ï¼‰ã€HumanEvalï¼ˆ0-shot@1ï¼‰å’Œ MBPPï¼ˆ3-shot@1ï¼‰ã€‚
- **Falcon-180B æ³¨æ„äº‹é¡¹**ï¼š ç”±äºæŠ€æœ¯é™åˆ¶ï¼ŒFalcon-180B æ²¡æœ‰åœ¨ QuAC å’Œ OBQA ä¸Šè¿›è¡Œæµ‹è¯•ã€‚è¯„æµ‹ç»“æœæ˜¯å…¶å®ƒä»»åŠ¡çš„å¹³å‡åˆ†æ•°ï¼Œé€šå¸¸è€Œè¨€ï¼Œ QuAC å’Œ OBQA çš„åˆ†æ•°è¾ƒä½ã€‚æœ¬æ¬¡è¯„ä¼°ç»“æœå¯èƒ½ç›¸å¯¹åˆç†åœ°åæ˜ äº† Falcon-180B çš„è¡¨ç°ï¼Œæ²¡æœ‰ä½ä¼°å®ƒçš„æ€§èƒ½ã€‚
</details>


#### Yi-9B

Yi-9B æ¨¡å‹åœ¨ Mistral-7Bã€SOLAR-10.7Bã€Gemma-7Bã€DeepSeek-Coder-7B-Base-v1.5 ç­‰ç›¸è¿‘å°ºå¯¸çš„æ¨¡å‹ä¸­ååˆ—å‰èŒ…ï¼Œå…·æœ‰å‡ºè‰²çš„ä»£ç èƒ½åŠ›ã€æ•°å­¦èƒ½åŠ›ã€å¸¸è¯†æ¨ç†èƒ½åŠ›ä»¥åŠé˜…è¯»ç†è§£èƒ½åŠ›ã€‚

![Yi-9B benchmark - details](https://github.com/01-ai/Yi/blob/main/assets/img/Yi-9B_benchmark_details.png?raw=true)

- åœ¨**ç»¼åˆ**èƒ½åŠ›æ–¹é¢ï¼ˆMean-Allï¼‰ï¼ŒYi-9B çš„æ€§èƒ½**åœ¨å°ºå¯¸ç›¸è¿‘çš„å¼€æºæ¨¡å‹ä¸­æœ€å¥½ï¼Œè¶…è¶Šäº†** DeepSeek-Coderã€DeepSeek-Mathã€Mistral-7Bã€SOLAR-10.7B å’Œ Gemma-7Bã€‚

![Yi-9B benchmark - overall](https://github.com/01-ai/Yi/blob/main/assets/img/Yi-9B_benchmark_overall.png?raw=true)

- åœ¨**ä»£ç **èƒ½åŠ›æ–¹é¢ï¼ˆMean-Codeï¼‰ï¼ŒYi-9B çš„æ€§èƒ½ä»…æ¬¡äº DeepSeek-Coder-7Bï¼Œ**è¶…è¶Šäº†** Yi-34Bã€SOLAR-10.7Bã€Mistral-7B å’Œ Gemma-7Bã€‚

![Yi-9B benchmark - code](https://github.com/01-ai/Yi/blob/main/assets/img/Yi-9B_benchmark_code.png?raw=true)

- åœ¨**æ•°å­¦**èƒ½åŠ›æ–¹é¢ï¼ˆMean-Mathï¼‰ï¼ŒYi-9B çš„æ€§èƒ½ä»…æ¬¡äº DeepSeek-Math-7Bï¼Œ**è¶…è¶Šäº†** SOLAR-10.7Bã€Mistral-7B å’Œ Gemma-7Bã€‚

![Yi-9B benchmark - math](https://github.com/01-ai/Yi/blob/main/assets/img/Yi-9B_benchmark_math.png?raw=true)

- åœ¨**å¸¸è¯†å’Œæ¨ç†**èƒ½åŠ›æ–¹é¢ï¼ˆMean-Textï¼‰ï¼ŒYi-9B çš„æ€§èƒ½ä¸ Mistral-7Bã€SOLAR-10.7B å’Œ Gemma-7B **ä¸ç›¸ä¸Šä¸‹**ã€‚

![Yi-9B benchmark - text](https://github.com/01-ai/Yi/blob/main/assets/img/Yi-9B_benchmark_text.png?raw=true)

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

## æŠ€æœ¯æŠ¥å‘Š

æ›´å¤šå…³äº Yi ç³»åˆ—æ¨¡å‹æ€§èƒ½çš„è¯¦ç»†ä¿¡æ¯ï¼Œå‚é˜… ã€Œ[Yiï¼šOpen Foundation Models by 01.AI](https://arxiv.org/abs/2403.04652)ã€ã€‚

### å¼•ç”¨

```
@misc{ai2024yi,
    title={Yi: Open Foundation Models by 01.AI},
    author={01. AI and : and Alex Young and Bei Chen and Chao Li and Chengen Huang and Ge Zhang and Guanwei Zhang and Heng Li and Jiangcheng Zhu and Jianqun Chen and Jing Chang and Kaidong Yu and Peng Liu and Qiang Liu and Shawn Yue and Senbin Yang and Shiming Yang and Tao Yu and Wen Xie and Wenhao Huang and Xiaohui Hu and Xiaoyi Ren and Xinyao Niu and Pengcheng Nie and Yuchi Xu and Yudong Liu and Yue Wang and Yuxuan Cai and Zhenyu Gu and Zhiyuan Liu and Zonghong Dai},
    year={2024},
    eprint={2403.04652},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
```

# ğŸ“Œ è°å¯ä»¥ä½¿ç”¨ Yiï¼Ÿ

ç­”æ¡ˆæ˜¯æ‰€æœ‰äºº! ğŸ™Œ âœ… 

å…³äºå¦‚ä½•ä½¿ç”¨ Yi ç³»åˆ—æ¨¡å‹ï¼Œå‚é˜…ã€Œ[è®¸å¯è¯](#è®¸å¯è¯)ã€ã€‚

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

# ğŸ“Œ å…¶å®ƒ

### è‡´è°¢

æˆ‘ä»¬å¯¹æ¯ä½ç«ç‚¬æ‰‹éƒ½æ·±è¡¨æ„Ÿæ¿€ï¼Œæ„Ÿè°¢ä½ ä»¬ä¸º Yi ç¤¾åŒºæ‰€åšçš„è´¡çŒ®ã€‚å› ä¸ºæœ‰ä½ ä»¬ï¼ŒYi ä¸ä»…æ˜¯ä¸€ä¸ªé¡¹ç›®ï¼Œè¿˜æˆä¸ºäº†ä¸€ä¸ªå……æ»¡æ´»åŠ›çš„åˆ›æ–°ç¤¾åŒºã€‚æˆ‘ä»¬ç”±è¡·åœ°æ„Ÿè°¢å„ä½å°ä¼™ä¼´ï¼

[![yi contributors](https://contrib.rocks/image?repo=01-ai/yi&max=2000&columns=15)](https://github.com/01-ai/yi/graphs/contributors)

#### æœ¬æ–‡è´¡çŒ®è€…
Yi Readme ä¸­æ–‡ç‰ˆç”±ä»¥ä¸‹[è´¡çŒ®è€…](https://github.com/01-ai/Yi/wiki/%F0%9F%93%9A-Yi-Translation-Plan#contributor-list)å®Œæˆï¼Œæ’åä¸åˆ†å…ˆåï¼Œä»¥ç”¨æˆ·åé¦–å­—æ¯é¡ºåºæ’åˆ—ã€‚
- Prompt ä¸“å®¶ï¼š[@kevinhall1998](https://github.com/kevinhall1998)
- è¯‘å‘˜ï¼š[@202030481266](https://github.com/202030481266)ã€[@GloriaLee01](https://github.com/GloriaLee01)ã€[@markli404](https://github.com/markli404)ã€[@petter529](https://github.com/petter529) ä¸ [@soulteary](https://github.com/soulteary)
- å®¡æ ¡ï¼š[@Anonymitaet](https://github.com/Anonymitaet)ã€[@bltcn](https://github.com/bltcn)ã€[@Cookize](https://github.com/Cookize)ã€[@lljzhgxd](https://github.com/lljzhgxd) ä¸ [@markli404](https://github.com/markli404)



<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### å…è´£å£°æ˜

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨æ•°æ®åˆè§„æ€§æ£€æŸ¥ç®—æ³•ï¼Œæœ€å¤§ç¨‹åº¦åœ°ç¡®ä¿è®­ç»ƒæ¨¡å‹çš„åˆè§„æ€§ã€‚ç”±äºæ•°æ®å¤æ‚ä¸”è¯­è¨€æ¨¡å‹ä½¿ç”¨åœºæ™¯å¤šæ ·ï¼Œæˆ‘ä»¬æ— æ³•ä¿è¯æ¨¡å‹åœ¨æ‰€æœ‰åœºæ™¯ä¸‹å‡èƒ½ç”Ÿæˆæ­£ç¡®åˆç†çš„å›å¤ã€‚æ³¨æ„ï¼Œæ¨¡å‹ä»å¯èƒ½ç”Ÿæˆæœ‰è¯¯çš„å›å¤ã€‚å¯¹äºä»»ä½•å› è¯¯ç”¨ã€è¯¯å¯¼ã€éæ³•ä½¿ç”¨ã€é”™è¯¯ä½¿ç”¨å¯¼è‡´çš„é£é™©å’Œé—®é¢˜ï¼Œä»¥åŠä¸ä¹‹ç›¸å…³çš„æ•°æ®å®‰å…¨é—®é¢˜ï¼Œæˆ‘ä»¬å‡ä¸æ‰¿æ‹…è´£ä»»ã€‚

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>

### è®¸å¯è¯

æœ¬ä»“åº“ä¸­çš„æºä»£ç éµå¾ª [Apache 2.0 è®¸å¯è¯](https://github.com/01-ai/Yi/blob/main/LICENSE)ã€‚Yi ç³»åˆ—æ¨¡å‹å®Œå…¨å¼€æ”¾ï¼Œä½ å¯ä»¥å…è´¹ç”¨äºä¸ªäººç”¨é€”ã€å­¦æœ¯ç ”ç©¶å’Œå•†ä¸šç”¨é€”ã€‚å¦‚éœ€å•†ç”¨ï¼Œä½ ä»…éœ€[æäº¤ç”³è¯·](https://www.lingyiwanwu.com/yi-license)ï¼Œå³èƒ½ç«‹åˆ»è‡ªåŠ¨è·å– Yi ç³»åˆ—æ¨¡å‹å•†ç”¨è®¸å¯ï¼Œè€Œæ— éœ€ç­‰å¾…å®˜æ–¹å®¡æ‰¹ã€‚æ‰€æœ‰ä½¿ç”¨å¿…é¡»éµå®ˆ[ã€ŠYiç³»åˆ—æ¨¡å‹ç¤¾åŒºè®¸å¯åè®® 2.1ã€‹](https://github.com/01-ai/Yi/blob/main/MODEL_LICENSE_AGREEMENT.txt)ã€‚

<p align="right"> [
  <a href="#top">è¿”å›é¡¶éƒ¨ â¬†ï¸ </a>  ] 
</p>



