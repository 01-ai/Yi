
# Yi-VL æœ€ä½³å®è·µ

## ç›®å½•
- [ç¯å¢ƒå‡†å¤‡](#ç¯å¢ƒå‡†å¤‡)
- [æ¨ç†](#æ¨ç†)
- [å¾®è°ƒ](#å¾®è°ƒ)
- [å¾®è°ƒåæ¨ç†](#å¾®è°ƒåæ¨ç†)

## å£°æ˜

æœ¬æ–‡ç« ä½œè€…ä¸º swift æˆå‘˜ Jintao Huangã€‚

åŸæ–‡é“¾æ¥ğŸ”—: https://github.com/modelscope/swift/blob/main/docs/source/Multi-Modal/yi-vlæœ€ä½³å®è·µ.md
## ç¯å¢ƒå‡†å¤‡
```shell
git clone https://github.com/modelscope/swift.git
cd swift
pip install -e '.[llm]'
```

## æ¨ç†

æ¨ç†[yi-vl-6b-chat](https://modelscope.cn/models/01ai/Yi-VL-6B/summary):
```shell
# Experimental environment: A10, 3090, V100...
# 18GB GPU memory
CUDA_VISIBLE_DEVICES=0 swift infer --model_type yi-vl-6b-chat
```

è¾“å‡º: (æ”¯æŒä¼ å…¥æœ¬åœ°è·¯å¾„æˆ–URL)
```python
"""
<<< æè¿°è¿™å¼ å›¾ç‰‡
Input a media path or URL <<< http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/cat.png
å›¾ç‰‡æ˜¾ç¤ºä¸€åªå°çŒ«ååœ¨åœ°æ¿ä¸Š,çœ¼ç›çå¼€,å‡è§†ç€æ‘„åƒæœºã€‚å°çŒ«çœ‹èµ·æ¥å¾ˆå¯çˆ±,æœ‰ç°è‰²å’Œç™½è‰²çš„æ¯›çš®,ä»¥åŠè“è‰²çš„çœ¼ç›ã€‚å®ƒä¼¼ä¹æ­£åœ¨çœ‹æ‘„åƒæœº,å¯èƒ½å¯¹å‘¨å›´ç¯å¢ƒå¾ˆå¥½å¥‡ã€‚
--------------------------------------------------
<<< ä½ æ˜¯è°ï¼Ÿ
Input a media path or URL <<<
æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹,éšæ—¶å‡†å¤‡å¸®åŠ©ä½ è§£ç­”é—®é¢˜æˆ–æä¾›ä¿¡æ¯ã€‚
--------------------------------------------------
<<< å›¾ä¸­æœ‰å‡ åªç¾Š
Input a media path or URL <<< http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/animal.png
å›¾ä¸­æœ‰å››åªç¾Š.
--------------------------------------------------
<<< clear
<<< è®¡ç®—ç»“æœæ˜¯å¤šå°‘
Input a media path or URL <<< http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/math.png
1452 + 45304 = 46756
--------------------------------------------------
<<< clear
<<< æ ¹æ®å›¾ç‰‡ä¸­çš„å†…å®¹å†™é¦–è¯—
Input a media path or URL <<< http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/poem.png
å¤œå¹•é™ä¸´,æ˜Ÿå…‰é—ªçƒ,
ä¸€è‰˜å°èˆ¹åœ¨æ²³ä¸Šé£˜è¡,
èˆ¹å¤´æŒ‚ç€ä¸€ç›æ˜äº®çš„ç¯,
ç…§äº®äº†å‘¨å›´çš„é»‘æš—ã€‚

èˆ¹ä¸Šæœ‰ä¸¤ä¸ªäºº,
ä¸€ä¸ªåœ¨èˆ¹å¤´,å¦ä¸€ä¸ªåœ¨èˆ¹å°¾,
ä»–ä»¬ä¼¼ä¹åœ¨è°ˆè¯,
åœ¨æ˜Ÿå…‰ä¸‹äº«å—ç€å®é™çš„æ—¶åˆ»ã€‚

æ²³å²¸è¾¹,æ ‘æœ¨åœ¨é»‘æš—ä¸­ç«™ç€,
åœ¨æ˜Ÿå…‰ä¸‹æŠ•ä¸‹é•¿é•¿çš„å½±å­ã€‚
è¿™æ™¯è±¡æ˜¯é‚£ä¹ˆçš„å®é™,
è®©äººæƒ³èµ·ä¸€ä¸ªå¤è€çš„ä¼ è¯´ã€‚

å°èˆ¹,äºº,å’Œæ˜Ÿå…‰,
æ„æˆäº†ä¸€ä¸ªç¾ä¸½çš„ç”»é¢,
å®ƒå”¤èµ·ä¸€ç§å®é™çš„æ„Ÿè§‰,
åœ¨å–§åš£çš„åŸå¸‚ç”Ÿæ´»ä¹‹å¤–ã€‚
--------------------------------------------------
<<< clear
<<< å¯¹å›¾ç‰‡è¿›è¡ŒOCR
Input a media path or URL <<< https://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/ocr.png
è¿™æ˜¯ä¸€æ®µå…³äºSWIFTçš„æ–‡å­—ï¼Œå…¶ä¸­åŒ…æ‹¬äº†å®ƒçš„ç‰ˆæœ¬ã€åŠŸèƒ½ä»¥åŠä¸€äº›é“¾æ¥ã€‚
"""
```

ç¤ºä¾‹å›¾ç‰‡å¦‚ä¸‹:

cat:

<img src="http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/cat.png" width="250" style="display: inline-block;">

animal:

<img src="http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/animal.png" width="250" style="display: inline-block;">

math:

<img src="http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/math.png" width="250" style="display: inline-block;">

poem:

<img src="http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/poem.png" width="250" style="display: inline-block;">

ocr:

<img src="https://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/ocr.png" width="250" style="display: inline-block;">

**å•æ ·æœ¬æ¨ç†**

```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from swift.llm import (
    get_model_tokenizer, get_template, inference, ModelType,
    get_default_template_type, inference_stream
)
from swift.utils import seed_everything
import torch

model_type = ModelType.yi_vl_6b_chat
template_type = get_default_template_type(model_type)
print(f'template_type: {template_type}')

model, tokenizer = get_model_tokenizer(model_type, torch.float16,
                                       model_kwargs={'device_map': 'auto'})
model.generation_config.max_new_tokens = 256
template = get_template(template_type, tokenizer)
seed_everything(2)  # ...

images = ['http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/road.png']
query = 'è·ç¦»å„åŸå¸‚å¤šè¿œï¼Ÿ'
response, history = inference(model, template, query, images=images)
print(f'query: {query}')
print(f'response: {response}')

# æµå¼
query = 'è·ç¦»æœ€è¿œçš„åŸå¸‚æ˜¯å“ªï¼Ÿ'
images = images * 2
gen = inference_stream(model, template, query, history, images=images)
print_idx = 0
print(f'query: {query}\nresponse: ', end='')
for response, history in gen:
    delta = response[print_idx:]
    print(delta, end='', flush=True)
    print_idx = len(response)
print()
print(f'history: {history}')
"""
query: è·ç¦»å„åŸå¸‚å¤šè¿œï¼Ÿ
response: è·ç¦»ç”²å¡”14å…¬é‡Œ,è·ç¦»é˜³æ±Ÿ62å…¬é‡Œ,è·ç¦»å¹¿å·293å…¬é‡Œ,è·ç¦»å¹¿å·293å…¬é‡Œã€‚
query: è·ç¦»æœ€è¿œçš„åŸå¸‚æ˜¯å“ªï¼Ÿ
response: æœ€è¿œçš„è·ç¦»æ˜¯293å…¬é‡Œã€‚
history: [['è·ç¦»å„åŸå¸‚å¤šè¿œï¼Ÿ', 'è·ç¦»ç”²å¡”14å…¬é‡Œ,è·ç¦»é˜³æ±Ÿ62å…¬é‡Œ,è·ç¦»å¹¿å·293å…¬é‡Œ,è·ç¦»å¹¿å·293å…¬é‡Œã€‚'], ['è·ç¦»æœ€è¿œçš„åŸå¸‚æ˜¯å“ªï¼Ÿ', 'æœ€è¿œçš„è·ç¦»æ˜¯293å…¬é‡Œã€‚']]
"""
```

ç¤ºä¾‹å›¾ç‰‡å¦‚ä¸‹:

road:

<img src="http://modelscope-open.oss-cn-hangzhou.aliyuncs.com/images/road.png" width="250" style="display: inline-block;">


## å¾®è°ƒ
å¤šæ¨¡æ€å¤§æ¨¡å‹å¾®è°ƒé€šå¸¸ä½¿ç”¨**è‡ªå®šä¹‰æ•°æ®é›†**è¿›è¡Œå¾®è°ƒ. è¿™é‡Œå±•ç¤ºå¯ç›´æ¥è¿è¡Œçš„demo:

(é»˜è®¤åªå¯¹LLMéƒ¨åˆ†çš„qkvè¿›è¡Œloraå¾®è°ƒ. å¦‚æœä½ æƒ³å¯¹æ‰€æœ‰linearå«visionæ¨¡å‹éƒ¨åˆ†éƒ½è¿›è¡Œå¾®è°ƒ, å¯ä»¥æŒ‡å®š`--lora_target_modules ALL`. æ”¯æŒå…¨å‚æ•°å¾®è°ƒ.)
```shell
# Experimental environment: A10, 3090, V100...
# 19GB GPU memory
CUDA_VISIBLE_DEVICES=0 swift sft \
    --model_type yi-vl-6b-chat \
    --dataset coco-en-2-mini \
```

[è‡ªå®šä¹‰æ•°æ®é›†](../LLM/è‡ªå®šä¹‰ä¸æ‹“å±•.md#-æ¨èå‘½ä»¤è¡Œå‚æ•°çš„å½¢å¼)æ”¯æŒjson, jsonlæ ·å¼, ä»¥ä¸‹æ˜¯è‡ªå®šä¹‰æ•°æ®é›†çš„ä¾‹å­:

(æ”¯æŒå¤šè½®å¯¹è¯, æ¯è½®å¯¹è¯é¡»åŒ…å«ä¸€å¼ å›¾ç‰‡æˆ–ä¸å«å›¾ç‰‡, æ”¯æŒä¼ å…¥æœ¬åœ°è·¯å¾„æˆ–URL)

```jsonl
{"query": "55555", "response": "66666", "images": ["image_path"]}
{"query": "eeeee", "response": "fffff", "history": [], "images": ["image_path"]}
{"query": "EEEEE", "response": "FFFFF", "history": [["AAAAA", "BBBBB"], ["CCCCC", "DDDDD"]], "images": ["image_path", "image_path2", "image_path3"]}
```


## å¾®è°ƒåæ¨ç†
ç›´æ¥æ¨ç†:
```shell
CUDA_VISIBLE_DEVICES=0 swift infer \
    --ckpt_dir output/yi-vl-6b-chat/vx-xxx/checkpoint-xxx \
    --load_dataset_config true \
```

**merge-lora**å¹¶æ¨ç†:
```shell
CUDA_VISIBLE_DEVICES=0 swift export \
    --ckpt_dir output/yi-vl-6b-chat/vx-xxx/checkpoint-xxx \
    --merge_lora true

CUDA_VISIBLE_DEVICES=0 swift infer \
    --ckpt_dir output/yi-vl-6b-chat/vx-xxx/checkpoint-xxx-merged \
    --load_dataset_config true
```
