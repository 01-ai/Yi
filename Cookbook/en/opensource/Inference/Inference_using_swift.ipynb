{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference with SWIFT\n",
    "\n",
    "SWIFT is an open-source framework from ModelScope that supports large model training, inference, evaluation, and deployment. With SWIFT, you can easily achieve a complete pipeline from model training to application.\n",
    "\n",
    "This tutorial will detail how to use SWIFT for inference, including installation steps and an inference example. We will use Yi-1.5-6B-Chat for demonstration.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ Run with Colab\n",
    "\n",
    "We provide a one-click [Colab script](https://colab.research.google.com/drive/1R0s7cDNWTNCWjod_z-jVpxiFc-R3_7kc?usp=drive_link) for running this tutorial directly in Colab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, we need to install the necessary dependencies.\n",
    "\n",
    "(Optional) You can set the global pip mirror to speed up downloads:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ms-swift:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install 'ms-swift[llm]' -U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Inference\n",
    "\n",
    "Before starting inference, note that your computer's memory and GPU memory should be sufficient. If not, you might encounter errors.\n",
    "\n",
    "| Model           | GPU Memory Usage | Disk Usage |\n",
    "| -------------- | ---------------- | ---------- |\n",
    "| Yi-1.5-6B-Chat | 11.5G            | 14.7G      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set the environment variable:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, load the model and tokenizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from swift.llm import (\n",
    "    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",
    ")\n",
    "from swift.utils import seed_everything\n",
    "\n",
    "# Select model type, here we use Yi-1.5-6B-Chat\n",
    "model_type = ModelType.yi_1_5_6b_chat\n",
    "template_type = get_default_template_type(model_type)\n",
    "print(f'template_type: {template_type}')  # Template type\n",
    "\n",
    "# Load model and tokenizer\n",
    "kwargs = {}\n",
    "model, tokenizer = get_model_tokenizer(model_type, model_kwargs={'device_map': 'auto'}, **kwargs)\n",
    "\n",
    "# Set generation config\n",
    "model.generation_config.max_new_tokens = 128\n",
    "\n",
    "# Get template\n",
    "template = get_template(template_type, tokenizer)\n",
    "\n",
    "# Set random seed\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform inference:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Prepare input query\n",
    "query = 'Hello!'\n",
    "\n",
    "# Perform inference using the template\n",
    "response, history = inference(model, template, query)\n",
    "\n",
    "# Print query and response\n",
    "print(f'query: {query}')\n",
    "print(f'response: {response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will output something like this:\n",
    "\n",
    "```\n",
    "query: Hello!\n",
    "response: Hi! How can I help you today?\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, you have learned how to perform inference using SWIFT with the Yi series models. If you encounter any issues, you can refer to the [SWIFT official documentation](https://www.modelscope.cn/models/01-ai/Yi-1.5-6B-Chat) for more help."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
