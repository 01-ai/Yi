{"cells":[{"cell_type":"markdown","metadata":{"id":"LUEkKPO5qaYL"},"source":["# Inference with SWIFT\n","\n","SWIFT is an open-source framework from ModelScope that supports large model training, inference, evaluation, and deployment. With SWIFT, you can easily achieve a complete pipeline from model training to application.\n","\n","This tutorial will detail how to use SWIFT for inference, including installation steps and an inference example. We will use Yi-1.5-6B-Chat for demonstration.\n"]},{"cell_type":"markdown","metadata":{"id":"wxnQfFs7qaYM"},"source":["## ðŸš€ Run with Colab\n"]},{"cell_type":"markdown","metadata":{"id":"6jdKJYrUqaYM"},"source":["## Installation\n","\n","First, we need to install the necessary dependencies.\n","\n","(Optional) You can set the global pip mirror to speed up downloads:\n"]},{"cell_type":"code","metadata":{"id":"c1q_HC8KqaYN"},"source":["!pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NQThi0GMqaYN"},"source":["Install ms-swift:\n"]},{"cell_type":"code","metadata":{"id":"xRcwIdKNqaYN"},"source":["!pip install 'ms-swift[llm]' -U"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OcE1ATZwqaYN"},"source":["## Start Inference\n","\n","Before starting inference, note that your computer's memory and GPU memory should be sufficient. If not, you might encounter errors.\n","\n","| Model           | GPU Memory Usage | Disk Usage |\n","| -------------- | ---------------- | ---------- |\n","| Yi-1.5-6B-Chat | 11.5G            | 14.7G      |\n"]},{"cell_type":"markdown","metadata":{"id":"cDDy2XaSqaYN"},"source":["First, set the environment variable:\n"]},{"cell_type":"code","metadata":{"id":"dN3HoqrtqaYN"},"source":["import os\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rDZY2KubqaYO"},"source":["Next, load the model and tokenizer:\n"]},{"cell_type":"code","metadata":{"id":"_UijGj08qaYO"},"source":["from swift.llm import (\n","    get_model_tokenizer, get_template, inference, ModelType, get_default_template_type,\n",")\n","from swift.utils import seed_everything\n","\n","# Select model type, here we use Yi-1.5-6B-Chat\n","model_type = ModelType.yi_1_5_6b_chat\n","template_type = get_default_template_type(model_type)\n","print(f'template_type: {template_type}')  # Template type\n","\n","# Load model and tokenizer\n","kwargs = {}\n","model, tokenizer = get_model_tokenizer(model_type, model_kwargs={'device_map': 'auto'}, **kwargs)\n","\n","# Set generation config\n","model.generation_config.max_new_tokens = 128\n","\n","# Get template\n","template = get_template(template_type, tokenizer)\n","\n","# Set random seed\n","seed_everything(42)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTWqG_DVqaYO"},"source":["Now, let's perform inference:\n"]},{"cell_type":"code","metadata":{"id":"T2KSI9U6qaYO"},"source":["# Prepare input query\n","query = 'Hello!'\n","\n","# Perform inference using the template\n","response, history = inference(model, template, query)\n","\n","# Print query and response\n","print(f'query: {query}')\n","print(f'response: {response}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6sH-TtA2qaYO"},"source":["The above code will output something like this:\n","\n","```\n","query: Hello!\n","response: Hi! How can I help you today?\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"tyYCjrhjqaYO"},"source":["With this, you have learned how to perform inference using SWIFT with the Yi series models. If you encounter any issues, you can refer to the [SWIFT official documentation](https://www.modelscope.cn/models/01-ai/Yi-1.5-6B-Chat) for more help."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}