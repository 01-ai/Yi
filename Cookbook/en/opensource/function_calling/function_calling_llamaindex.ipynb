{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORfgxDEFPG125uYS1AUVbE"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Function Calling\n",
        "\n",
        "The main purpose of Function Calling in large models is to extend their capabilities, allowing them to integrate a wider range of information and functions when generating text, making decisions, or performing tasks. By defining and calling external functions, large models can handle more complex tasks, such as performing mathematical operations, placing orders, or querying databases, thereby improving their practicality and flexibility.\n"
      ],
      "metadata": {
        "id": "tY2fLItjnn6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸŒŸUsing LlamaIndex\n",
        "\n",
        "LlamaIndex has developed an easy-to-use method for Function Calling. Let's use `yi-large` for an example.\n",
        "\n",
        "First, let's install the dependencies. Follow along step by step!\n"
      ],
      "metadata": {
        "id": "EiQrQO8In5W2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install llama-index\n",
        "!pip install llama-index-llms-huggingface\n",
        "!pip install llama-index-llms-yi"
      ],
      "metadata": {
        "id": "9-f7jfstpCEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the installation is complete, and then we'll get started.\n",
        "\n",
        "Load the dependencies."
      ],
      "metadata": {
        "id": "3tlgHR5spMhG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9F41myGnfCS"
      },
      "outputs": [],
      "source": [
        "from typing import Any\n",
        "\n",
        "from llama_index.core.llms import (\n",
        "    CustomLLM,\n",
        "    CompletionResponse,\n",
        "    CompletionResponseGen,\n",
        "    LLMMetadata,\n",
        ")\n",
        "from llama_index.core.llms.callbacks import llm_completion_callback\n",
        "from llama_index.llms.yi import Yi\n",
        "\n",
        "from llama_index.core.tools import FunctionTool\n",
        "from llama_index.core.agent import ReActAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the model. Here, we load the open-source model from Huggingface. You can also download `Yi-1.5-34B-Chat` directly from Huggingface.\n"
      ],
      "metadata": {
        "id": "xBu4fAuapTMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=2048,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name='/model/Yi-1.5-9B-Chat', # Load local model\n",
        "    model_name='/model/Yi-1.5-9B-Chat', # Load local model\n",
        "    device_map=\"auto\",\n",
        "    model_kwargs={\"torch_dtype\": torch.float16},\n",
        ")"
      ],
      "metadata": {
        "id": "Lq4QFDl-pLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the tools. Here, we define three functions: `add`, `subtract`, and `multiply`.\n"
      ],
      "metadata": {
        "id": "gCnRQ2vNpViR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the tools\n",
        "def multiply(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers and return the result.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "def add(a: int, b: int) -> int:\n",
        "    \"\"\"Add two integers and return the result.\"\"\"\n",
        "    return a + b\n",
        "\n",
        "def subtract(a: int, b: int) -> int:\n",
        "    \"\"\"Subtract two integers and return the result.\"\"\"\n",
        "    return a - b\n",
        "\n",
        "multiply_tool = FunctionTool.from_defaults(fn=multiply)\n",
        "add_tool = FunctionTool.from_defaults(fn=add)\n",
        "subtract_tool = FunctionTool.from_defaults(fn=subtract)"
      ],
      "metadata": {
        "id": "g5-zAq22pXu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the agent\n"
      ],
      "metadata": {
        "id": "cvUFnsAkph-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ReActAgent.from_tools([multiply_tool, add_tool, subtract_tool], llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "Hurvg2J1pjQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure everything runs correctly, and then we'll start a conversation\n"
      ],
      "metadata": {
        "id": "kEkZMzaXplsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_input = input(\"user>>\") # \"(1+2)*10\"\n",
        "    agent.chat(user_input)"
      ],
      "metadata": {
        "id": "Ki3NKbq_pqTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see the results\n"
      ],
      "metadata": {
        "id": "HjcL_f7npr-K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "``````\n",
        "user>>(1+2)*10\n",
        "Thought: The user's question is in English. I need to use a combination of the 'add' and 'multiply' tools to solve the mathematical expression (1+2)*10.\n",
        "Action: add\n",
        "Action Input: {'a': 1, 'b': 2}\n",
        "Observation: 3\n",
        "Thought: I have the result of the 'add' operation, which is 3. Now I need to multiply this result by 10 to complete the expression (1+2)*10.\n",
        "Action: multiply\n",
        "Action Input: {'a': 3, 'b': 10}\n",
        "Observation: 30\n",
        "Thought: I have the result of the 'multiply' operation, which is 30. This is the final result of the expression (1+2)*10.\n",
        "Thought: I can answer without using any more tools. I'll use the user's language to answer.\n",
        "Answer: The result of the expression (1+2)*10 is 30.\n",
        "``````"
      ],
      "metadata": {
        "id": "oBUz2VtkpuUw"
      }
    }
  ]
}
